{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***| Cristian Meichtry (62529) | Juan Martin Rodriguez (62563) |*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luego de iterar sobre varios diseños, se probaron dos modelos principales:\n",
    "\n",
    "***Primer modelo***: Consta de 4 bloques convolucionales y capas densas finales. Utiliza activaciones SELU, Batch Normalization, Dropout, ruido gaussiano y regularización L2. Optimiza con Adam y clasifica con softmax. Obtuvo un score privado de 0.6954 y un score público de 0.7108.\n",
    "\n",
    "***Segundo modelo***: Es una red residual profunda con bloques que integran convoluciones, Batch Normalization y conexiones residuales. Incluye etapas de inicialización, procesamiento intermedio y reducción espacial, seguidas de capas densas con Swish y regularización. También utiliza Adam como optimizador. Este modelo logró un score privado de 0.6766 y un score público de 0.6808.\n",
    "\n",
    "Por otro lado, se observó que, de manera contraintuitiva, al aplicar data augmentation similar al del TP1, el rendimiento disminuía notablemente, alcanzando scores cercanos a 0.58."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.397134Z",
     "iopub.status.busy": "2024-11-26T15:14:03.396756Z",
     "iopub.status.idle": "2024-11-26T15:14:03.405224Z",
     "shell.execute_reply": "2024-11-26T15:14:03.404242Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.397101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\n",
      "/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\n",
      "/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\n",
      "/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\n",
      "/kaggle/input/dl-itba-cifar-100-2024-q-1/x_test.npy\n",
      "/kaggle/input/dl-itba-cifar-100-2024-q-1/x_train.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.406940Z",
     "iopub.status.busy": "2024-11-26T15:14:03.406689Z",
     "iopub.status.idle": "2024-11-26T15:14:03.932796Z",
     "shell.execute_reply": "2024-11-26T15:14:03.931916Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.406916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 15  4 ...  8  7  1]\n",
      "[19 29  0 ...  3  7 73]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/x_train.npy\")/255.\n",
    "x_test = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/x_test.npy\")/255.\n",
    "y_train_coarse = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\")\n",
    "y_train_fine = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\")\n",
    "\n",
    "print(y_train_coarse)\n",
    "print(y_train_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.934668Z",
     "iopub.status.busy": "2024-11-26T15:14:03.934062Z",
     "iopub.status.idle": "2024-11-26T15:14:03.940089Z",
     "shell.execute_reply": "2024-11-26T15:14:03.939215Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.934629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\", \"rb\") as f:\n",
    "    labels_fine = pickle.load(f)\n",
    "with open(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\", \"rb\") as f:\n",
    "    labels_coarse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.956272Z",
     "iopub.status.busy": "2024-11-26T15:14:03.955983Z",
     "iopub.status.idle": "2024-11-26T15:14:03.966205Z",
     "shell.execute_reply": "2024-11-26T15:14:03.965384Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.956246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#%load_ext tensorboard\n",
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.967625Z",
     "iopub.status.busy": "2024-11-26T15:14:03.967160Z",
     "iopub.status.idle": "2024-11-26T15:14:03.977104Z",
     "shell.execute_reply": "2024-11-26T15:14:03.976343Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.967598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#This code snippet visualizes samples from the training dataset.\n",
    "#It displays two rows of images with their corresponding labels, each consisting of eight images.\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "cant = 8\n",
    "for i in range(cant):\n",
    "    plt.subplot(1, cant, i+1)\n",
    "    plt.imshow(x_train[i]) #Display the i-th image from the training set\n",
    "    plt.title([labels_fine[y_train[i]] ])\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(cant):\n",
    "    plt.subplot(1, cant, i+1)\n",
    "    plt.imshow(x_train[i+cant]) #Display the image at index i + cant in x_train\n",
    "    plt.title([labels_fine[y_train[i+cant]]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.978674Z",
     "iopub.status.busy": "2024-11-26T15:14:03.978352Z",
     "iopub.status.idle": "2024-11-26T15:14:03.987698Z",
     "shell.execute_reply": "2024-11-26T15:14:03.986944Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.978637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:03.989659Z",
     "iopub.status.busy": "2024-11-26T15:14:03.988754Z",
     "iopub.status.idle": "2024-11-26T15:14:03.997671Z",
     "shell.execute_reply": "2024-11-26T15:14:03.997032Z",
     "shell.execute_reply.started": "2024-11-26T15:14:03.989620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_split_train, x_split_val, y_split_train, y_split_val = train_test_split(x_train, y_train_fine, test_size=0.2, stratify=y_train_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_split_train))\n",
    "print(len(x_split_val))\n",
    "print(len(y_split_train))\n",
    "print(len(y_split_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "cant = 8\n",
    "for i in range(cant):\n",
    "    plt.subplot(1, cant, i+1)\n",
    "    plt.imshow(x_split_train[i]) #Display the i-th image from the training set\n",
    "    plt.title([labels_fine[y_split_train[i]] ])\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(cant):\n",
    "    plt.subplot(1, cant, i+1)\n",
    "    plt.imshow(x_split_train[i+cant]) #Display the image at index i + cant in x_split_train\n",
    "    plt.title([labels_fine[y_split_train[i+cant]]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:04.044125Z",
     "iopub.status.busy": "2024-11-26T15:14:04.043863Z",
     "iopub.status.idle": "2024-11-26T15:14:04.057107Z",
     "shell.execute_reply": "2024-11-26T15:14:04.056445Z",
     "shell.execute_reply.started": "2024-11-26T15:14:04.044101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,AveragePooling2D,Activation,Add, Dropout, GaussianNoise, BatchNormalization, Flatten, Input, Rescaling, Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, Normalization, RandomBrightness, RandomFlip, RandomContrast, RandomFlip, RandomRotation, RandomCrop\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:04.083443Z",
     "iopub.status.busy": "2024-11-26T15:14:04.082683Z",
     "iopub.status.idle": "2024-11-26T15:14:04.707902Z",
     "shell.execute_reply": "2024-11-26T15:14:04.707193Z",
     "shell.execute_reply.started": "2024-11-26T15:14:04.083405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "net_input = Input(shape=(32,32,3))\n",
    "\n",
    "def res_block_first(input_layer,filters=16):\n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(input_layer)\n",
    "    aux_net=BatchNormalization()(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(aux_net)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(net)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(net)\n",
    "    net=BatchNormalization()(net)\n",
    "    \n",
    "    net=Add()([aux_net,net])\n",
    "    \n",
    "    net=Activation(\"relu\")(net)\n",
    "    net=MaxPooling2D()(net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "def res_block(input_layer,filters=16):\n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(input_layer)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(net)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(net)\n",
    "    net=BatchNormalization()(net)\n",
    "\n",
    "    net=Add()([input_layer,net])\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "def res_block_dec(input_layer,filters=32):\n",
    "    \n",
    "    input_layer=MaxPooling2D()(input_layer)\n",
    "    net=Conv2D(filters=filters, kernel_size=(1, 1), padding='same')(input_layer)\n",
    "    aux_net=BatchNormalization()(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(input_layer)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(net)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    net=Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(net)\n",
    "    net=BatchNormalization()(net)\n",
    "    net=Add()([aux_net,net])\n",
    "    net=Activation(\"relu\")(net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "net=res_block_first(net_input,filters=128)\n",
    "net=res_block(net,filters=128)\n",
    "net=res_block(net,filters=128)\n",
    "net=res_block(net,filters=128)\n",
    "\n",
    "net=res_block_dec(net,filters=256)\n",
    "net=res_block(net,filters=256)\n",
    "net=res_block(net,filters=256)\n",
    "net=res_block(net,filters=256)\n",
    "\n",
    "net=res_block_dec(net,filters=512)\n",
    "net=res_block(net,filters=512)\n",
    "net=res_block(net,filters=512)\n",
    "net=res_block(net,filters=512)\n",
    "\n",
    "net = AveragePooling2D(pool_size = (2,2)) (net)\n",
    "\n",
    "net=Flatten()(net)\n",
    "\n",
    "net=Dense(units=2048, activation='swish')(net)\n",
    "net=Dropout(0.3)(net)\n",
    "net=Dense(units=1000, activation='swish')(net)\n",
    "net = BatchNormalization(momentum=0.95, \n",
    "        epsilon=0.005,\n",
    "        beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n",
    "        gamma_initializer=Constant(value=0.9))(net)\n",
    "net=Dense(units=100, activation = 'softmax')(net)\n",
    "\n",
    "model=Model(net_input,net)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up learning rate reduction on plateau to optimize training stability.\n",
    "\n",
    "rlrop = ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",  # Monitors validation accuracy to detect plateaus\n",
    "    factor=0.5,              # Reduces the learning rate by half when plateauing\n",
    "    patience=3,              # Waits for 3 epochs without improvement before reducing the learning rate\n",
    "    verbose=1,               # Enables detailed output for each reduction in learning rate\n",
    "    min_lr=1e-5              # Defines a minimum learning rate to prevent over-reduction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:04.757172Z",
     "iopub.status.busy": "2024-11-26T15:14:04.756907Z",
     "iopub.status.idle": "2024-11-26T15:14:04.769621Z",
     "shell.execute_reply": "2024-11-26T15:14:04.768907Z",
     "shell.execute_reply.started": "2024-11-26T15:14:04.757148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sets up a model checkpoint to save the best weights during training.\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    \"best_weights.weights.h5\",   # Path to save the model weights file.\n",
    "    monitor=\"val_accuracy\",      # Monitors validation accuracy to determine when to save\n",
    "    verbose=1,                   # Prints a message each time the model weights are saved\n",
    "    save_best_only=True,         # Saves only if validation accuracy improves, keeping the best weights\n",
    "    save_weights_only=True       # Saves only the model weights, not the full model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:04.770699Z",
     "iopub.status.busy": "2024-11-26T15:14:04.770461Z",
     "iopub.status.idle": "2024-11-26T15:14:04.788133Z",
     "shell.execute_reply": "2024-11-26T15:14:04.787415Z",
     "shell.execute_reply.started": "2024-11-26T15:14:04.770676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sets up early stopping to monitor the validation accuracy during training.\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",       # Tracks validation accuracy to determine stopping point\n",
    "    patience=10,                  # High patience value (40 epochs) to enable longer training\n",
    "    verbose=1,                    # Prints messages to indicate when early stopping is triggered\n",
    "    restore_best_weights=True     # Restores model weights from the best validation accuracy epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:04.789778Z",
     "iopub.status.busy": "2024-11-26T15:14:04.789071Z",
     "iopub.status.idle": "2024-11-26T15:14:04.798097Z",
     "shell.execute_reply": "2024-11-26T15:14:04.797390Z",
     "shell.execute_reply.started": "2024-11-26T15:14:04.789740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(\n",
    "    log_dir=\"logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:05.180019Z",
     "iopub.status.busy": "2024-11-26T15:14:05.179630Z",
     "iopub.status.idle": "2024-11-26T15:14:05.535481Z",
     "shell.execute_reply": "2024-11-26T15:14:05.534805Z",
     "shell.execute_reply.started": "2024-11-26T15:14:05.179950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  \n",
    "            samplewise_center=False,  \n",
    "            featurewise_std_normalization=False,  \n",
    "            samplewise_std_normalization=False,  \n",
    "            zca_whitening=False, \n",
    "            rotation_range=0,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_split_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:14:05.536889Z",
     "iopub.status.busy": "2024-11-26T15:14:05.536619Z",
     "iopub.status.idle": "2024-11-26T16:55:35.111754Z",
     "shell.execute_reply": "2024-11-26T16:55:35.110991Z",
     "shell.execute_reply.started": "2024-11-26T15:14:05.536863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "I0000 00:00:1732634080.165378      93 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_25', 4 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_23', 4 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_13', 4 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.0382 - loss: 6.4187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02770, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 82ms/step - accuracy: 0.0427 - loss: 6.2014 - val_accuracy: 0.0277 - val_loss: 7.4095 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.1009 - loss: 4.4481\n",
      "Epoch 2: val_accuracy improved from 0.02770 to 0.07000, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.1036 - loss: 4.4346 - val_accuracy: 0.0700 - val_loss: 113.3101 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.1584 - loss: 4.1695\n",
      "Epoch 3: val_accuracy improved from 0.07000 to 0.17390, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.1601 - loss: 4.1477 - val_accuracy: 0.1739 - val_loss: 6.3543 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.2063 - loss: 3.7934\n",
      "Epoch 4: val_accuracy improved from 0.17390 to 0.20180, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.2091 - loss: 3.7815 - val_accuracy: 0.2018 - val_loss: 4.9357 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.2571 - loss: 3.5044\n",
      "Epoch 5: val_accuracy improved from 0.20180 to 0.29280, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.2598 - loss: 3.4875 - val_accuracy: 0.2928 - val_loss: 4.0326 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.3016 - loss: 3.2643\n",
      "Epoch 6: val_accuracy improved from 0.29280 to 0.30690, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.3017 - loss: 3.2642 - val_accuracy: 0.3069 - val_loss: 3.1036 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.3344 - loss: 3.0914\n",
      "Epoch 7: val_accuracy did not improve from 0.30690\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.3350 - loss: 3.0852 - val_accuracy: 0.3005 - val_loss: 42.5695 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.3754 - loss: 2.8366\n",
      "Epoch 8: val_accuracy did not improve from 0.30690\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.3751 - loss: 2.8370 - val_accuracy: 0.2338 - val_loss: 338.2352 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.3914 - loss: 2.7517\n",
      "Epoch 9: val_accuracy improved from 0.30690 to 0.31240, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.3902 - loss: 2.7568 - val_accuracy: 0.3124 - val_loss: 88.9786 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.4068 - loss: 2.6671\n",
      "Epoch 10: val_accuracy improved from 0.31240 to 0.41000, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.4072 - loss: 2.6622 - val_accuracy: 0.4100 - val_loss: 2.6093 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.4478 - loss: 2.4542\n",
      "Epoch 11: val_accuracy improved from 0.41000 to 0.42570, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.4481 - loss: 2.4529 - val_accuracy: 0.4257 - val_loss: 2.5392 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.4685 - loss: 2.3286\n",
      "Epoch 12: val_accuracy did not improve from 0.42570\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.4695 - loss: 2.3237 - val_accuracy: 0.4239 - val_loss: 5.0112 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.5011 - loss: 2.1852\n",
      "Epoch 13: val_accuracy improved from 0.42570 to 0.46420, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 2.1887 - val_accuracy: 0.4642 - val_loss: 2.4646 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.5167 - loss: 2.0929\n",
      "Epoch 14: val_accuracy did not improve from 0.46420\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.5150 - loss: 2.1014 - val_accuracy: 0.4266 - val_loss: 3.5886 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.5434 - loss: 1.9708\n",
      "Epoch 15: val_accuracy improved from 0.46420 to 0.48010, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.5412 - loss: 1.9769 - val_accuracy: 0.4801 - val_loss: 2.4441 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.5669 - loss: 1.8398\n",
      "Epoch 16: val_accuracy did not improve from 0.48010\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.5667 - loss: 1.8408 - val_accuracy: 0.4316 - val_loss: 6.4029 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.5921 - loss: 1.7181\n",
      "Epoch 17: val_accuracy improved from 0.48010 to 0.50810, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.5913 - loss: 1.7216 - val_accuracy: 0.5081 - val_loss: 2.2145 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.6186 - loss: 1.6075\n",
      "Epoch 18: val_accuracy did not improve from 0.50810\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.6170 - loss: 1.6121 - val_accuracy: 0.5071 - val_loss: 2.1959 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.6382 - loss: 1.5008\n",
      "Epoch 19: val_accuracy improved from 0.50810 to 0.50910, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.6374 - loss: 1.5046 - val_accuracy: 0.5091 - val_loss: 2.2035 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.6640 - loss: 1.3857\n",
      "Epoch 20: val_accuracy improved from 0.50910 to 0.53180, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.6620 - loss: 1.3921 - val_accuracy: 0.5318 - val_loss: 2.1407 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.6827 - loss: 1.3065\n",
      "Epoch 21: val_accuracy improved from 0.53180 to 0.53700, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.6810 - loss: 1.3149 - val_accuracy: 0.5370 - val_loss: 2.1559 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.7069 - loss: 1.2258\n",
      "Epoch 22: val_accuracy improved from 0.53700 to 0.56010, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.7047 - loss: 1.2332 - val_accuracy: 0.5601 - val_loss: 2.0234 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.7249 - loss: 1.1551\n",
      "Epoch 23: val_accuracy did not improve from 0.56010\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.7229 - loss: 1.1623 - val_accuracy: 0.5473 - val_loss: 2.0532 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.7436 - loss: 1.0837\n",
      "Epoch 24: val_accuracy did not improve from 0.56010\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.7420 - loss: 1.0886 - val_accuracy: 0.5328 - val_loss: 2.2464 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.7633 - loss: 1.0096\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.56010\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.7615 - loss: 1.0167 - val_accuracy: 0.5520 - val_loss: 2.4565 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.8183 - loss: 0.7902\n",
      "Epoch 26: val_accuracy improved from 0.56010 to 0.59210, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.8196 - loss: 0.7811 - val_accuracy: 0.5921 - val_loss: 1.8925 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8482 - loss: 0.6341\n",
      "Epoch 27: val_accuracy improved from 0.59210 to 0.60400, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.8478 - loss: 0.6349 - val_accuracy: 0.6040 - val_loss: 1.9235 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8676 - loss: 0.5680\n",
      "Epoch 28: val_accuracy improved from 0.60400 to 0.60450, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.8665 - loss: 0.5717 - val_accuracy: 0.6045 - val_loss: 1.9293 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8802 - loss: 0.5215\n",
      "Epoch 29: val_accuracy improved from 0.60450 to 0.61320, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.8791 - loss: 0.5244 - val_accuracy: 0.6132 - val_loss: 1.9756 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8884 - loss: 0.4866\n",
      "Epoch 30: val_accuracy did not improve from 0.61320\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.8873 - loss: 0.4903 - val_accuracy: 0.5735 - val_loss: 2.2457 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8953 - loss: 0.4613\n",
      "Epoch 31: val_accuracy did not improve from 0.61320\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.8943 - loss: 0.4649 - val_accuracy: 0.6105 - val_loss: 2.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9034 - loss: 0.4369\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.61320\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9027 - loss: 0.4386 - val_accuracy: 0.5993 - val_loss: 2.2423 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9248 - loss: 0.3533\n",
      "Epoch 33: val_accuracy improved from 0.61320 to 0.62060, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9260 - loss: 0.3480 - val_accuracy: 0.6206 - val_loss: 2.0597 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9459 - loss: 0.2645\n",
      "Epoch 34: val_accuracy improved from 0.62060 to 0.62710, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9455 - loss: 0.2651 - val_accuracy: 0.6271 - val_loss: 2.0453 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9521 - loss: 0.2351\n",
      "Epoch 35: val_accuracy did not improve from 0.62710\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9515 - loss: 0.2365 - val_accuracy: 0.6212 - val_loss: 2.0856 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9511 - loss: 0.2302\n",
      "Epoch 36: val_accuracy did not improve from 0.62710\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9512 - loss: 0.2307 - val_accuracy: 0.6234 - val_loss: 2.1294 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9531 - loss: 0.2205\n",
      "Epoch 37: val_accuracy improved from 0.62710 to 0.62960, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9532 - loss: 0.2205 - val_accuracy: 0.6296 - val_loss: 2.1166 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9590 - loss: 0.2018\n",
      "Epoch 38: val_accuracy did not improve from 0.62960\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9584 - loss: 0.2035 - val_accuracy: 0.6219 - val_loss: 2.1612 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9582 - loss: 0.1998\n",
      "Epoch 39: val_accuracy did not improve from 0.62960\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9581 - loss: 0.2005 - val_accuracy: 0.6155 - val_loss: 2.2722 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9622 - loss: 0.1889\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.62960\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9618 - loss: 0.1896 - val_accuracy: 0.6192 - val_loss: 2.2770 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9709 - loss: 0.1584\n",
      "Epoch 41: val_accuracy improved from 0.62960 to 0.63090, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9714 - loss: 0.1565 - val_accuracy: 0.6309 - val_loss: 2.2128 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9776 - loss: 0.1346\n",
      "Epoch 42: val_accuracy improved from 0.63090 to 0.63270, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.9773 - loss: 0.1340 - val_accuracy: 0.6327 - val_loss: 2.1747 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.9790 - loss: 0.1196\n",
      "Epoch 43: val_accuracy did not improve from 0.63270\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9790 - loss: 0.1195 - val_accuracy: 0.6319 - val_loss: 2.2185 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9798 - loss: 0.1166\n",
      "Epoch 44: val_accuracy improved from 0.63270 to 0.63290, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.9797 - loss: 0.1165 - val_accuracy: 0.6329 - val_loss: 2.2217 - learning_rate: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9817 - loss: 0.1043\n",
      "Epoch 45: val_accuracy did not improve from 0.63290\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9815 - loss: 0.1049 - val_accuracy: 0.6305 - val_loss: 2.2036 - learning_rate: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9819 - loss: 0.1053\n",
      "Epoch 46: val_accuracy did not improve from 0.63290\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9816 - loss: 0.1057 - val_accuracy: 0.6312 - val_loss: 2.2591 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9810 - loss: 0.1044\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.63290\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9810 - loss: 0.1046 - val_accuracy: 0.6299 - val_loss: 2.2625 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9849 - loss: 0.0880\n",
      "Epoch 48: val_accuracy improved from 0.63290 to 0.63500, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 77ms/step - accuracy: 0.9853 - loss: 0.0873 - val_accuracy: 0.6350 - val_loss: 2.2108 - learning_rate: 6.2500e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9868 - loss: 0.0823\n",
      "Epoch 49: val_accuracy did not improve from 0.63500\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9869 - loss: 0.0820 - val_accuracy: 0.6347 - val_loss: 2.2050 - learning_rate: 6.2500e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9886 - loss: 0.0747\n",
      "Epoch 50: val_accuracy improved from 0.63500 to 0.63760, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.9884 - loss: 0.0749 - val_accuracy: 0.6376 - val_loss: 2.2199 - learning_rate: 6.2500e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9873 - loss: 0.0747\n",
      "Epoch 51: val_accuracy did not improve from 0.63760\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9873 - loss: 0.0743 - val_accuracy: 0.6346 - val_loss: 2.2285 - learning_rate: 6.2500e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9885 - loss: 0.0701\n",
      "Epoch 52: val_accuracy did not improve from 0.63760\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9886 - loss: 0.0698 - val_accuracy: 0.6370 - val_loss: 2.2368 - learning_rate: 6.2500e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9891 - loss: 0.0674\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.63760\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9891 - loss: 0.0675 - val_accuracy: 0.6344 - val_loss: 2.2655 - learning_rate: 6.2500e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9897 - loss: 0.0623\n",
      "Epoch 54: val_accuracy did not improve from 0.63760\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9898 - loss: 0.0625 - val_accuracy: 0.6372 - val_loss: 2.2131 - learning_rate: 3.1250e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9907 - loss: 0.0616\n",
      "Epoch 55: val_accuracy improved from 0.63760 to 0.63950, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9908 - loss: 0.0610 - val_accuracy: 0.6395 - val_loss: 2.1953 - learning_rate: 3.1250e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9914 - loss: 0.0573\n",
      "Epoch 56: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9914 - loss: 0.0572 - val_accuracy: 0.6394 - val_loss: 2.2287 - learning_rate: 3.1250e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9927 - loss: 0.0537\n",
      "Epoch 57: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9926 - loss: 0.0538 - val_accuracy: 0.6384 - val_loss: 2.2397 - learning_rate: 3.1250e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9929 - loss: 0.0519\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9929 - loss: 0.0518 - val_accuracy: 0.6386 - val_loss: 2.2517 - learning_rate: 3.1250e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9919 - loss: 0.0523\n",
      "Epoch 59: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9919 - loss: 0.0523 - val_accuracy: 0.6389 - val_loss: 2.2428 - learning_rate: 1.5625e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9926 - loss: 0.0510\n",
      "Epoch 60: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9928 - loss: 0.0507 - val_accuracy: 0.6384 - val_loss: 2.2450 - learning_rate: 1.5625e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9936 - loss: 0.0471\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9935 - loss: 0.0474 - val_accuracy: 0.6379 - val_loss: 2.2456 - learning_rate: 1.5625e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9941 - loss: 0.0463\n",
      "Epoch 62: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9941 - loss: 0.0463 - val_accuracy: 0.6369 - val_loss: 2.2305 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9937 - loss: 0.0454\n",
      "Epoch 63: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9936 - loss: 0.0457 - val_accuracy: 0.6385 - val_loss: 2.2529 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9934 - loss: 0.0462\n",
      "Epoch 64: val_accuracy did not improve from 0.63950\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9936 - loss: 0.0458 - val_accuracy: 0.6385 - val_loss: 2.2400 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9942 - loss: 0.0449\n",
      "Epoch 65: val_accuracy improved from 0.63950 to 0.63980, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.9942 - loss: 0.0447 - val_accuracy: 0.6398 - val_loss: 2.2203 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9949 - loss: 0.0422\n",
      "Epoch 66: val_accuracy did not improve from 0.63980\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9948 - loss: 0.0424 - val_accuracy: 0.6393 - val_loss: 2.2185 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9936 - loss: 0.0441\n",
      "Epoch 67: val_accuracy improved from 0.63980 to 0.63990, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 77ms/step - accuracy: 0.9937 - loss: 0.0441 - val_accuracy: 0.6399 - val_loss: 2.2157 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9935 - loss: 0.0444\n",
      "Epoch 68: val_accuracy did not improve from 0.63990\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9936 - loss: 0.0444 - val_accuracy: 0.6393 - val_loss: 2.2090 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9934 - loss: 0.0443\n",
      "Epoch 69: val_accuracy improved from 0.63990 to 0.64060, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9934 - loss: 0.0445 - val_accuracy: 0.6406 - val_loss: 2.2205 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9934 - loss: 0.0434\n",
      "Epoch 70: val_accuracy improved from 0.64060 to 0.64070, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9935 - loss: 0.0433 - val_accuracy: 0.6407 - val_loss: 2.2129 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9938 - loss: 0.0420\n",
      "Epoch 71: val_accuracy did not improve from 0.64070\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9939 - loss: 0.0419 - val_accuracy: 0.6402 - val_loss: 2.2053 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9938 - loss: 0.0418\n",
      "Epoch 72: val_accuracy did not improve from 0.64070\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9938 - loss: 0.0418 - val_accuracy: 0.6406 - val_loss: 2.2277 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9941 - loss: 0.0424\n",
      "Epoch 73: val_accuracy did not improve from 0.64070\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9941 - loss: 0.0423 - val_accuracy: 0.6381 - val_loss: 2.2287 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9948 - loss: 0.0409\n",
      "Epoch 74: val_accuracy did not improve from 0.64070\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9947 - loss: 0.0410 - val_accuracy: 0.6395 - val_loss: 2.2412 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9948 - loss: 0.0409\n",
      "Epoch 75: val_accuracy did not improve from 0.64070\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9948 - loss: 0.0409 - val_accuracy: 0.6407 - val_loss: 2.2124 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9948 - loss: 0.0392\n",
      "Epoch 76: val_accuracy improved from 0.64070 to 0.64080, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9947 - loss: 0.0393 - val_accuracy: 0.6408 - val_loss: 2.2061 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9950 - loss: 0.0388\n",
      "Epoch 77: val_accuracy did not improve from 0.64080\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9950 - loss: 0.0388 - val_accuracy: 0.6398 - val_loss: 2.2091 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9942 - loss: 0.0405\n",
      "Epoch 78: val_accuracy did not improve from 0.64080\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9941 - loss: 0.0407 - val_accuracy: 0.6396 - val_loss: 2.2320 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9948 - loss: 0.0381\n",
      "Epoch 79: val_accuracy did not improve from 0.64080\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9948 - loss: 0.0382 - val_accuracy: 0.6403 - val_loss: 2.2228 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9945 - loss: 0.0390\n",
      "Epoch 80: val_accuracy improved from 0.64080 to 0.64110, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9946 - loss: 0.0389 - val_accuracy: 0.6411 - val_loss: 2.2196 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9946 - loss: 0.0394\n",
      "Epoch 81: val_accuracy did not improve from 0.64110\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9946 - loss: 0.0392 - val_accuracy: 0.6396 - val_loss: 2.2239 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9943 - loss: 0.0397\n",
      "Epoch 82: val_accuracy did not improve from 0.64110\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9943 - loss: 0.0397 - val_accuracy: 0.6409 - val_loss: 2.2068 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9944 - loss: 0.0392\n",
      "Epoch 83: val_accuracy did not improve from 0.64110\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9944 - loss: 0.0389 - val_accuracy: 0.6404 - val_loss: 2.2105 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9937 - loss: 0.0413\n",
      "Epoch 84: val_accuracy did not improve from 0.64110\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9938 - loss: 0.0411 - val_accuracy: 0.6401 - val_loss: 2.2343 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9955 - loss: 0.0374\n",
      "Epoch 85: val_accuracy did not improve from 0.64110\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9955 - loss: 0.0373 - val_accuracy: 0.6407 - val_loss: 2.2353 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9950 - loss: 0.0364\n",
      "Epoch 86: val_accuracy improved from 0.64110 to 0.64150, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9950 - loss: 0.0368 - val_accuracy: 0.6415 - val_loss: 2.2278 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9954 - loss: 0.0355\n",
      "Epoch 87: val_accuracy did not improve from 0.64150\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9954 - loss: 0.0356 - val_accuracy: 0.6399 - val_loss: 2.2186 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9951 - loss: 0.0370\n",
      "Epoch 88: val_accuracy did not improve from 0.64150\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9951 - loss: 0.0371 - val_accuracy: 0.6414 - val_loss: 2.2164 - learning_rate: 1.0000e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9956 - loss: 0.0356\n",
      "Epoch 89: val_accuracy improved from 0.64150 to 0.64210, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9956 - loss: 0.0356 - val_accuracy: 0.6421 - val_loss: 2.2205 - learning_rate: 1.0000e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9954 - loss: 0.0355\n",
      "Epoch 90: val_accuracy did not improve from 0.64210\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9954 - loss: 0.0355 - val_accuracy: 0.6399 - val_loss: 2.2248 - learning_rate: 1.0000e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9954 - loss: 0.0349\n",
      "Epoch 91: val_accuracy did not improve from 0.64210\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9954 - loss: 0.0350 - val_accuracy: 0.6409 - val_loss: 2.2107 - learning_rate: 1.0000e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9952 - loss: 0.0358\n",
      "Epoch 92: val_accuracy improved from 0.64210 to 0.64330, saving model to best_weights.weights.h5\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 76ms/step - accuracy: 0.9953 - loss: 0.0356 - val_accuracy: 0.6433 - val_loss: 2.2124 - learning_rate: 1.0000e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9965 - loss: 0.0334\n",
      "Epoch 93: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9964 - loss: 0.0336 - val_accuracy: 0.6413 - val_loss: 2.2163 - learning_rate: 1.0000e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9958 - loss: 0.0331\n",
      "Epoch 94: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9958 - loss: 0.0331 - val_accuracy: 0.6400 - val_loss: 2.2132 - learning_rate: 1.0000e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9959 - loss: 0.0325\n",
      "Epoch 95: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9960 - loss: 0.0327 - val_accuracy: 0.6414 - val_loss: 2.2152 - learning_rate: 1.0000e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9949 - loss: 0.0362\n",
      "Epoch 96: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9950 - loss: 0.0361 - val_accuracy: 0.6414 - val_loss: 2.2254 - learning_rate: 1.0000e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9959 - loss: 0.0332\n",
      "Epoch 97: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9958 - loss: 0.0333 - val_accuracy: 0.6417 - val_loss: 2.2229 - learning_rate: 1.0000e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9951 - loss: 0.0346\n",
      "Epoch 98: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9951 - loss: 0.0346 - val_accuracy: 0.6397 - val_loss: 2.2352 - learning_rate: 1.0000e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9959 - loss: 0.0345\n",
      "Epoch 99: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 74ms/step - accuracy: 0.9959 - loss: 0.0346 - val_accuracy: 0.6396 - val_loss: 2.2331 - learning_rate: 1.0000e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m625/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.9956 - loss: 0.0334\n",
      "Epoch 100: val_accuracy did not improve from 0.64330\n",
      "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 75ms/step - accuracy: 0.9956 - loss: 0.0332 - val_accuracy: 0.6414 - val_loss: 2.2299 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 92.\n"
     ]
    }
   ],
   "source": [
    "# Trains the model using the fit method and logs the training history.\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_split_train, y_split_train, batch_size=64),\n",
    "    steps_per_epoch=x_split_train.shape[0]//50,                               \n",
    "    epochs=100,                                     # Specifies the maximum number of training epochs.\n",
    "    validation_data=(x_split_val, y_split_val),       # Uses validation set to track the model’s performance.\n",
    "    callbacks=[                                     \n",
    "        rlrop,  # Reduces learning rate on plateau if validation performance stops improving\n",
    "        es,     # Implements early stopping with patience, restoring the best weights\n",
    "        mc,     # Saves the model weights when the best validation accuracy is reached\n",
    "        tb,     # Enables tensorboard logging for visualizing the training process\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:35.113289Z",
     "iopub.status.busy": "2024-11-26T16:55:35.112959Z",
     "iopub.status.idle": "2024-11-26T16:55:35.310209Z",
     "shell.execute_reply": "2024-11-26T16:55:35.309277Z",
     "shell.execute_reply.started": "2024-11-26T16:55:35.113256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f63cbc36ad0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Train loss\")\n",
    "\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:35.311689Z",
     "iopub.status.busy": "2024-11-26T16:55:35.311425Z",
     "iopub.status.idle": "2024-11-26T16:55:35.561718Z",
     "shell.execute_reply": "2024-11-26T16:55:35.560926Z",
     "shell.execute_reply.started": "2024-11-26T16:55:35.311663Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f63c85ab460>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdS0lEQVR4nO3dd5RU9f3/8ef03WUrbKMsLL1IU5pALChxbViiCSoREMWfCn41aFSigsYoJpYQo9FoIkQjoiaiKJbgIlaUuhTpsHS2AdvLzM7c3x93d5aFBbbPltfjnDkzc+/n3vueyzD3vZ92LYZhGIiIiIgEiDXQAYiIiEjrpmREREREAkrJiIiIiASUkhEREREJKCUjIiIiElBKRkRERCSglIyIiIhIQCkZERERkYCyBzqA6vD5fBw6dIiwsDAsFkugwxEREZFqMAyDvLw8OnTogNV66vqPZpGMHDp0iISEhECHISIiIrWwf/9+OnXqdMr1zSIZCQsLA8wPEx4eHuBoREREpDpyc3NJSEjwX8dPpVkkI+VNM+Hh4UpGREREmpkzdbFQB1YREREJKCUjIiIiElBKRkRERCSglIyIiIhIQCkZERERkYBSMiIiIiIBpWREREREAkrJiIiIiARUjZORr7/+mnHjxtGhQwcsFgsffPDBGbdZvnw555xzDi6Xix49ejB//vxahCoiIiItUY2TkYKCAgYNGsRLL71UrfKpqalcccUVjBkzhpSUFO69915uu+02Pv/88xoHKyIiIi1PjaeDv+yyy7jsssuqXf6VV16ha9euPPfccwD07duXb7/9lj//+c8kJSXV9PAiIiLSwjR4n5EVK1YwduzYSsuSkpJYsWLFKbcpKSkhNze30kNERERapga/UV5aWhpxcXGVlsXFxZGbm0tRURHBwcEnbTNnzhwef/zxhg5NRETqyOcz8BoGXp/5KPUZJy2zWCAqxEmQw1blPkpKveQUejAAC+ZN1SwWsFosWDCfsYDVAi67DYfNUuWN17w+g2KPF7vNgtNmrVTG6zM4UlBCRm4JmXklGBiEuhyEuuyEBdlxOawUu30UuEspKCmlwO3FMAyCHDZcditBDhsOm5Uit5e8Yg95JaXkFZfi8fpw2Kw4bBbsVit2mwWbxYLNan4Gm9WModRr4PH6KPWZzx6vgbvUh7vUi7vsvWEYGAb4DDAwz2Opr+I8GkBksIOoNk7atnESFeLEbrNQ7PFS7PFR7PHiLvXhsFsJsltxOWwE2c3zYJbxUuTxUuLx4fb6cJf6ymLx4fYa3DS8M/ERQfX/JamGJnnX3pkzZzJjxgz/+/JbEIuI1IXPZ3C00E1WfglHC9wUub0Uur0Uuc0faYfNSkSwg8gQBxHBDoKdNo4VmOUz891k5pVQ4vGCBSxYsFrAAPKKPeQUlZJT5CGnyIPX5yPEaaeN00aIy06Iw0ah2+tfn1PkodBdCoBhnDpeiwUcNitOuxWnzWpe9OxW7FaL+bBZsFmtGGU7OX5f5ddha9kLd6mP4lLzolXi8eIzDOw2c1/Osn2W+swLZEmpeaFyl12ojr+Q+qo4VnWFuey0C3USHeoC4EjZuc0rLq3RfqwWCHLYCHbYsForLrQeb0VQNquFYIeNIIcNiwWO5Jfgq0XMrcmY3jEtNxmJj48nPT290rL09HTCw8OrrBUBcLlcuFyuhg5NRJo4wzD/MiwpNS+gbq+PgpLSShf1nEIPRwvcZOa7OZJfQlZ+CfklpSfsB7KLzHJeXZEajc1q1hL4yv4d80pKySspZc+RwpPKlteEGIZxxqTBZ0BhWSJ5Kl6fQX5JaaXvgtUC7UJdxIa5sFos/vX5xaUUebyEOG1mEukyny2YtTbFHh8lpWatQxuX3V+bEhrkwGmz4PEalPp8eEoNPD4fPp/5GbzHJW8Om1lr4iirPfEnmXYrrrJ11rIaITCf7VazhsV8tmJg+L/vxwrdHClw4/OV1d44bAQ7rDjtNtylXkpKff7E08BM3oIcVoLs5rPLbsNhN2t0nGWxtGsTuOtugycjI0eO5JNPPqm0bOnSpYwcObKhDy0iAVBS6mXL4TyOFbjJLnJzrMBDdpGHghLzB7/Y7aW47Ifdbj3uB9lupdjjIzO/hKy8EjLLai8aInloW1bN3cZpI9hp/oUd7LThLjXILfKQXeQ2ay9KvES1cRJd9td8TJiLEKetUlW6YUB4kJ3wYEdZrYpZdV5Y4qXAXUphSSmFHi/BDhsRZWUigh2EOO1Yy3rtmY0RJ/MZZo2Eu6ymoqSslsLrM2spSr3mRd5s2ih7lO3LrOY3a24Mw8BZ1tQQVFZ1b7OaF1GzxsNsJjAvTDZcjuNqYmwWfw1KeRNEec1QeQJhs1iwWsFutWK1clwzRVkshkFucSlZZf+2WfluAKJDnbQLdREd6iQ8yIHVWvk8+MqaJsoTFJ9RkZgWe3wUebx4fYZ5kS2rKXE5rJT6DIrLa73KysSGuWjbxondVnVXScMwqmz6kcZR42QkPz+fnTt3+t+npqaSkpJC27Zt6dy5MzNnzuTgwYO88cYbANxxxx28+OKLPPDAA0yZMoVly5bx7rvvsmTJkvr7FCIScAeOFbLgx328s2o/RwrcDXIMh82seo8oa0aJDHYSEeygbRszWTCbAMwL24nX9/AgBzFlFyTHKS5I0jAsFos/CeseE1rt7SqSk4p/zCCHDYIdZ9w2POjMZU6MUQKnxsnI6tWrGTNmjP99ed+OSZMmMX/+fA4fPsy+ffv867t27cqSJUv4zW9+w1/+8hc6derEP/7xDw3rFWniij1eMnJLKPJ4/f0FvGV/QXuP61SXV1LK4pSDLNua4a9ejwpx0CEymKgQJxEhDiKDHYQFOcra8K0EO204bVY83rL+CV4fJR4fTruVmDCzBiKmLLkIcdj9f6mf+JeziLQMFsOoTTekxpWbm0tERAQ5OTmEh4cHOhyRZqvY42VXZj7b0vLYnVlAoduL21vRuz63yMPhnGLScovJLvTUeP8/6xHNr8/twti+saesDheR1qO61+8mOZpGROrH4Zwivt2RxXc7s9hwMIc9WQU1GlEQ5LDSxmnHftywRXMkh9nnwBzNYeHshCgmnNu5RlXwIiLllIyItDCHsot49evdfL0jk92ZBSetjwh20Ds+jB6xoYQHOXAd14E01GUnPiKI9hHBxEcEER5kV1u6iDQ4JSMiLcjOjHx+/Y8fScstBsyhjAM7RfKzHtEMTYyib/twYsNcSjBEpElRMiLSQmw6mMPE11dytMBNz9hQ7rukNyO7tSMipGajCkREGpuSEZEWYPWeo9wyfxV5xaUM6BjBv6YMp20bZ6DDEhGpFiUjIs2Y12ewfFsG0xeso8jjZXhiW/45eShhNZxjQUQkkJSMiDQDhmFwrNDDoewi9hwpYMOBHNbvz2bTwRwKyqbEvqBXDK/8egjBzqpvRiYi0lQpGRFpYnKKPKTsz2bdvmOk7M9m35FCDuUUUezxVVk+2GHj6sEdePzqs3DZlYiISPOjZEQkQHw+g/3HCtmRns/2jDx2pOfz06EcdmTkn/KOqNGhTjpGhdC/QziDOkUyKCGSHrGh/tuUi4g0R0pGRBrBsQI3a/cdY3t6PjvS89iekcfOjPxT1nZ0bhvCOZ0jOadLFD1iQ+lQNu9HkEM1HyLS8igZEWkgHq+P5dsy+c+a/SzbmoHHe3J1h9NupXtMKD1jQ+kVF0rv+HAGJ0QSExa4W3mLiDQ2JSMi9SynyMOLy3awaN1B/63SAbrHtKFfhwh6xYbSMy6MXnGhdG4bonu4iEirp2REpB7lFXuY+M8fWX8gBzD7eFwzuCPXDelE3/a6yaOISFWUjIjUkyK3l1vnr2b9gRyiQhw8fd1ALuoTi0M1HyIip6VkRKQelJR6uf3N1azcc5Qwl503poxgQKeIQIclItIs6E82kTryeH1MX7COb3ZkEeywMX/KMCUiIiI1oGREpI4e/M8Glm5Ox2m38o9JQxnSpW2gQxIRaVaUjIjUwfr92by/7iA2q4VXfn0Oo3tEBzokEZFmR8mISB3M+y4VgKsHdeCiPnEBjkZEpHlSMiJSS+m5xXy84TAAt4zuGuBoRESaLyUjIrX05oq9lPoMhie2VYdVEZE6UDIiUgvFHi8LVu4D4JbRiYENRkSkmVMyIlILH6Yc5GiBm46Rwfy8n/qKiIjUhZIRkRoyDIPXv90DwKRRXXRvGRGROtKvqEgNfb/rCNvS8whx2hg/tHOgwxERafaUjIjUUPlw3uuHdCIixBHgaEREmj8lIyI1kJpVQPLWDAAmjUoMbDAiIi2EkhGRatqensed/16DYcCY3jF0jwkNdEgiIi2C7torcgaGYfDGir089ckWSkp9tGvj5LdJfQIdlohIi6FkROQ0svJLeOA/G1hW1jRzYe8Ynrl+EDFhrgBHJiLScigZEalCqdfHO6v38/z/tnOkwI3TbmXmZX2YPCoRi8US6PBERFoUJSMiJ/h6eyZPLtnCtvQ8AHrHhfGXGwfTJz48wJGJiLRMSkZEyuzOzOeJjzfz5bZMACJDHNx7cU8mnNsFhyY2ExFpMEpGpNUr9nh5efkuXl6+C7fXh91qYeLIRP7v4h5EhjgDHZ6ISIunZERate93ZfHIok3szioAzA6qs67sRzcN2xURaTRKRqRVKnJ7eeSDTfx37QEAYsJcPDbuLC4fEK8OqiIijUzJiLQ6he5Sbp2/mhW7j2CxwM3nduH+pN6EB2lqdxGRQFAyIq1KfkkpU+atYuWeo4S67Lw2cSgju7cLdFgiIq2akhFpNXKLPUx+fSVr92UTFmTnX1OGc07nqECHJSLS6ikZkVYhp9DDxNd/ZP2BHCKCHfz71hEM6BQR6LBERAQlI9IKFHu8TJ6/kvUHcmjbxsm/bx1Bvw6awExEpKlQMiItmmEYPPLBJtbtyyYi2MHbU8+ld3xYoMMSEZHjaFpJadHmf7+H/6w5gNUCL910jhIREZEmSMmItFjf7cziD0u2APDwFf34Wc/oAEckIiJVUTIiLdK+I4VMW7AWr8/gunM6MWV0YqBDEhGRU1AyIi1OQUkpU99YTXahh0EJkTx5bX/Nqioi0oQpGZEWZ+4X29mWnkdsmItXbx5CkMMW6JBEROQ0lIxIi7I9PY953+0B4I/XDyQuPCiwAYmIyBkpGZEWwzAMZn24iVKfQdJZcYzpHRvokEREpBqUjEiLsXj9IX7YfZQgh5VHr+wX6HBERKSalIxIi5BX7OHJsmG808f0oFNUSIAjEhGR6lIyIi3CC8k7yMgrIbFdCFPP7xbocEREpAaUjEizty0tj9fLOq0+dtVZuOwaPSMi0pwoGZFm7w9LNuMt67R6oTqtiog0O0pGpFkr9nj5ftcRAB68tE+AoxERkdpQMiLN2vb0PLw+g7ZtnHSNbhPocEREpBaUjEiztvlQLgD92odryncRkWZKyYg0az+VJSNndQgPcCQiIlJbtUpGXnrpJRITEwkKCmLEiBGsXLnytOXnzp1L7969CQ4OJiEhgd/85jcUFxfXKmCR420+XFYzomRERKTZqnEy8s477zBjxgxmz57N2rVrGTRoEElJSWRkZFRZfsGCBTz00EPMnj2bLVu28M9//pN33nmH3/3ud3UOXlo3n89gy+GKZhoREWmeapyMPP/880ydOpVbbrmFfv368corrxASEsLrr79eZfnvv/+e0aNHc9NNN5GYmMgll1zCjTfeeMbaFJEz2XOkgEK3lyCHlW4xoYEOR0REaqlGyYjb7WbNmjWMHTu2YgdWK2PHjmXFihVVbjNq1CjWrFnjTz52797NJ598wuWXX16HsEUqmmh6x4djs6rzqohIc2WvSeGsrCy8Xi9xcXGVlsfFxbF169Yqt7npppvIysriZz/7GYZhUFpayh133HHaZpqSkhJKSkr873Nzc2sSprQSx4+kERGR5qvBR9MsX76cp556ir/97W+sXbuW999/nyVLlvDEE0+ccps5c+YQERHhfyQkJDR0mNIMaSSNiEjLUKOakejoaGw2G+np6ZWWp6enEx8fX+U2jz76KDfffDO33XYbAAMGDKCgoIDbb7+dhx9+GKv15Hxo5syZzJgxw/8+NzdXCYmcRCNpRERahhrVjDidToYMGUJycrJ/mc/nIzk5mZEjR1a5TWFh4UkJh81m3sjMMIwqt3G5XISHh1d6iBwvI6+YzLwSrBboG6/vh4hIc1ajmhGAGTNmMGnSJIYOHcrw4cOZO3cuBQUF3HLLLQBMnDiRjh07MmfOHADGjRvH888/z9lnn82IESPYuXMnjz76KOPGjfMnJSI1Vd5fpGt0G4Kd+h6JiDRnNU5Gxo8fT2ZmJrNmzSItLY3Bgwfz2Wef+Tu17tu3r1JNyCOPPILFYuGRRx7h4MGDxMTEMG7cOJ588sn6+xTS6lQ00UQEOBIREakri3GqtpImJDc3l4iICHJyctRkIwBMW7CWJRsO89Blfbjjgu6BDkdERKpQ3eu37k0jzdIWDesVEWkxlIxIs1NQUkrqkQJAI2lERFoCJSPS7GxNy8UwIC7cRXSoK9DhiIhIHSkZkWZHM6+KiLQsSkak2dFkZyIiLYuSEWl2KqaB17BeEZGWQMmINCulXh9b0/IANdOIiLQUSkakWdmdVYC71Eeoy07ntiGBDkdEROqBkhFpVtbvzwagb/swrFZLYIMREZF6oWREmo3cYg9zv9gBwPCubQMcjYiI1BclI9JszP7wJw5mF9GlXQh3Xdgj0OGIiEg9UTIizcJH6w+xaN1BrBZ4/leDaeOq8T0eRUSkiVIyIk3e4ZwiHl60EYDpF/VkSJeoAEckIiL1ScmINGk+n8F9764nt7iUQZ0iuPsiNc+IiLQ0SkakSXv9u1S+33WEYIeNP48fjMOmr6yISEujX3ZpsnZl5vOnz7cB8MiVfekWExrgiEREpCEoGZEmyeczeOi/G3CX+ji/Vww3De8c6JBERKSBKBmRJumtlftYtecYIU4bT13bH4tFE5yJiLRUSkakyTmcU8QfP90KwG+TetMpStO+i4i0ZEpGpEkxDINHFm0iv6SUsztHMnFkYqBDEhGRBqZkRJqUjzccJnlrBg6bhT9eNxCb7j8jItLiKRmRJuNYgZvHFv8EwLQxPegVFxbgiEREpDEoGZEm47GPfuJIgZuesaHceWH3QIcjIiKNRMmINAkfbzjEhymHsFrgT9cPxGW3BTokERFpJEpGJOAycot55INNgNk8c3Zn3XtGRKQ1UTIiAWUYBg/8dwPZhR76dwzn7ot6BjokERFpZEpGJKAWrNzH8m2ZOO1W/vyrwTjt+kqKiLQ2+uWXgNmTVcAfPt4CwANJvemp0TMiIq2SkhEJCK/P4L731lPk8XJut7ZMGd010CGJiEiAKBmRgHhn1X7W7D1GqMvOs78chFWTm4mItFpKRqTRHStw86fPzXvP3HdJL917RkSklVMyIo3uuaXbyC700DsujJvP7RLocEREJMCUjEij2nQwh7d+3AfA41efhd2mr6CISGunK4E0Gp/PYNaHmzAMuGpQB87t1i7QIYmISBOgZEQazaJ1B1m7L5sQp43fXd430OGIiEgToWREGkVusYc5n5qdVv/v4p7ERwQFOCIREWkqlIxIo3j+f9vJyi+hW3QbzSkiIiKVKBmRBrcy9Sj/WrEHgMeuOktTvouISCW6KkiDKnJ7eeA/6zEM+NXQTpzfKybQIYmISBOjZEQa1DOfb2PPkULiw4N4+Ip+gQ5HRESaICUj0mBW7TnKvO9TAZhz3QAigh0BjkhERJoiJSPSIIrcXn77XkXzzJjesYEOSUREmiglI9Ignv2fmmdERKR6lIxIvVuz9yivf6fmGRERqR4lI1Kvij1eHvjPBgwDfjlEzTMiInJmSkakXv112Q52ZRYQE+biETXPiIhINSgZkXqz6WAOr3y1G4Anru5PRIiaZ0REKjEMyD0MJfmBjqRJsQc6AGkZPF4fD/xnA16fwRUD2nNp//hAhyTSuhgGFB2D/HRwF4DhM5cZPsAAmwscwWWPELBYwVsCpSVQWgxeD0R1geCoMx/L54PCI1CQAUXZYHjLjlf2cLSBkLYQ0s7cn9V2+n15CqAkD4pzoDi37DkHrFYI72g+wtqDzW5+ppI883PmpYE73/xM9uCKz2d3gdUBNifYHGCxgLvQLOspNM9PcS6UHHes0hIIi4fIBIjobD4bBuQehJwD5nPe4bLt8syHO988RkwfiO0DMX2hXQ/wlULRUfMcFR6F7H2QvgnSfzKfi3PMzx7WAaJ7QLue0K67efyw9hAaZ772FEPeIcgtexRmgVHpHx18XvC6yx4e8/xHdobonuZ+o7qY5+BE3lLIPQBHd8PRVDiWCufdV71//wagZETqxatf72bz4VwiQxw8dtVZgQ5HmrpSt/nDHtHp9Beq6vAUQ9Y2SN8MGT+Zz3mHzYutxVL2bAVnqHlxLL9IusLMH25fqXlB9JWCz2P+oJf/uPtKK1/kyi/k9iDzuXxZcFTFfp2h5kUsP828CGXvNy9kPs8JcRdBXrpZLi/dvLhCxTEcQeYFtfziWf6w2sDZpuJhdZhJQV66mVzUVURniB8A7QeaF8b8dPNCmHfY/Bz5GVCQZSYg1eWKMC+IVnvZw2ae5/ILeuUrbNUsVmgTa27jKaj1x2sQWxbXrLzFan738g6Zj9SvGyYuMM93SLR5zsv/TxiG+e/pK61ctu/VkDCs4WI5DSUjUmc7M/L5S/IOAGZd2Y+YMFeAI5KAKs6Bw+vBYqv4y9Rqh6O74MAq2L8KDqeYf407w6DTUEgYAZ1HmBf5tE2QvtH8K/JoqvmXXftB0H4wdBhsljm4Bg6sNp/Tf6rZhbGhWcv+Cj0x+ahPJbmnXhccZZ5Xq7UiEQMzAfQUmkmQpxCztsRpnk+7yyyXnw45+8zHtiVnjiOkHQS3Pe5CZwUsZoJRdLSiBqAk58z7stggKAKCwsueIyr+es89ZF4489MqyjvDzNoDV5hZq+H/bEUVyWSl74WlIoFzhJjHcZUfK9L8nuYegpz9ZhLpLmtGcYaaNTMRnSC8vVnWFW4e1xVqJkcZWyBzK2RsBXeeuZ3VXnF+wuIh7iwzyYvrD9G9zIQqaycc2QFZO8yaCX9ymlb2b4SZSIR3MB9tYk5O3o//f2ZzmknOsT3mfo/sMvdz/Hk7ns1l/v+K6gptu0Jw5Jn/nRqIkhGpE8MweOSDjbhLfVzQK4Zrz+4Y6JCknLfUvKiUV8GWlpg/vOU/wM5Q86JWeMSs3i88al7AYs+C+P4QkWD+FVUdhgF7v4O1b8LmD6G06MzbWKzmD/fuL83HqRQdhUPrTr+v4Cgz7rh+ENvP/IHFclxThdesXj++6rwkt+KvdKv95B91m9M8H8df6NyF5mfzHPdwF0Bxtrnf0uKKJMRiMy9ikQnmhcx+QpJuc0JofFnVfDyExprblCcLniJzX44Q89/KGWK+NgzzQlZeU+J1mxep0Djz4Qg687k3DPNhPaHbYFE2pG0se2wwa0DC4s0LYVh787n8OG2iq67+P5631PxuFWeX1TyVPbyl5rausIqHPejU3zefr6z257D5/Q2LN5OKM/F5K5ouHME1+z4XHTPLB0XWbLuCTPOzuMJOv53dadZCVFUTYRgVTUAnfm9qwldW+1J4pKLJzjAAo+x71+Hk70CAWAzDqEb9WGDl5uYSERFBTk4O4eHhgQ5HjrN0czpT31iNy24l+b4L6BQVEuiQmq/M7WbtQc9L6tZ0sem/8OUcsy24LjUGQRHmhd1iMy/c5VXqPm9Zm3aceTENjoQdS83Yy0UkmD/I5e3YXrd5MUsYBp2GQafhEJUImVtg3w+w/0fYv9Lcd3x/86/IuP5mO/rR3XAoxaxNOZRi7q/D2dDxHLNWpeMQ86Jf3QtGQ3IXmj/8UNHHQaQVq+71W8mI1JrH6yNp7tfszizgrgu788ClfQIdUtNwNNW8OHccAp2GnLn8gdXw7Z9h68fm+/iBcPkz0Pncmh3XMOC7v8AXsyuW2YPMi35UV/MvyeM77JXkm1XVwW3L+ju0Nf8aT//JrHI+sT35TBxtoP8v4JxJZpLQEMlB+c9VU0g8ROSMqnv9VtoutbZw1X52ZxbQro2TOy/sHuhwAu/ILvjmOVi/sKJGovNIGDkdel9WubajKNusCfj+BdjzTdlCi1kNn7YBXk+CAb+En//erBo/E58XPv8d/PiK+f7cu2DU3WbNRW2qYUvdZqfQzG1mc8rx1elQNpKhrH07P9McSXDWtRXrG4qSEJEWSTUjUit5xR7GPLucrHw3v7/6LCaOTAx0SIFzdDcs/yNsfLdsGCVmZ8v0nyr6D7TtBt0vhiM7zVqHvMMV21vtMHA8jL7H7PCW/HtY+wZgmLUNo+6Gc+849ZA7TzEsut3sqwFwyZMwanpDfVoRkWpTM400qGc/38aLX+6kW3QbPv/N+ThsTaMTVKPLPQx/O9fsoAdmf48LHjSbKXIPwcpXYfXrFaMKjhfeEfqOM2tOIhMqrzu0Dj55AA6sNN+7wmH4VDh3GrRpZzZXHNkFO5fC+rfN0Ss2J1zzMgy4vkE/sohIdSkZkQZzOKeIMc8up9jj4+83DyHprFY8wdl7k+GnReZIjqtfNDtVnqgk30wYju0xh/TF9oWY3mYH0dMxDHPfXz8DGZvNZY420OsSOLgWsvdWlHWFww1vQdfz6+uTiYjUmfqMSIN57n/bKfb4GJYYxSX94gIdTu3kHIAfXjYv3r2SarePnV+YyYLFCte+bM6FURVXqFmrUVMWi9khtN815pwPX/3J7E/y0yJzvc1p9knpMdYsF9Gpdp9DRCTAlIxIjWw+lMt/1x4A4HeX98XS3DoUGobZH+N/j5gjS9b9G367s+r5Enxe+PQBs6/GBQ9VHqbpKYIl95uvR9xx6kSkPlitZnNOnyvNUToHVkLHoZD4MzPRERFp5mrV0P/SSy+RmJhIUFAQI0aMYOXKlactn52dzbRp02jfvj0ul4tevXrxySef1CpgCRzDMHjso58wDLhyYHvO7hyYexjUWvY+ePNa+Oj/KmawLM6G1K+qLr/rS1j1D7OZZMGvzEmzyn3zvDmRWFgHGPO7Bg8dMGtKel0CFz0CvS9VIiIiLUaNa0beeecdZsyYwSuvvMKIESOYO3cuSUlJbNu2jdjY2JPKu91ufv7znxMbG8t//vMfOnbsyN69e4mMjKyP+KURfbThMCtTjxLksDLz8r6BDufUPEVm7UfO/sqzZO78wpy0yx4EFz1qTpe8Zr45CqXH2JP3s/Hdite7ks3htje9Y45e+fbP5vLLnm744awiIi1cjTuwjhgxgmHDhvHiiy8C4PP5SEhI4O677+ahhx46qfwrr7zCM888w9atW3E4andLeXVgDbxCdykXPfsVabnF3PfzXtx9cc9Ah1S1omOw4AbY/0PV6xPOhatfMu+UufsreOMqc9Kv+7dXbqpxF8IzPcxpty9/Fr5+1pxTo00sRHQ0R7v0vARueldzX4iInEKDdGB1u92sWbOGmTNn+pdZrVbGjh3LihUrqtxm8eLFjBw5kmnTpvHhhx8SExPDTTfdxIMPPojNVvWU1yUlJZSUVNx9Mjf3NDeFkkbxty93kZZbTELbYKae3y3Q4VQt5yD8+zpzivGgCDj75rKbYpXdBTW8Y+XJx7qMNm9CVZhlTjzW/aKKfW37xExEohJh2G3Q+3JYMN68gVtBhlm7ctmflIiIiNSDGiUjWVlZeL1e4uIqj6CIi4tj69atVW6ze/duli1bxoQJE/jkk0/YuXMnd911Fx6Ph9mzZ1e5zZw5c3j88cdrEpo0oL1HCnj1690APHJFP4Icdbzle0PI3AZv/sK8w2dYe/j1f837m5yOzW52DF0zz2yqOT4Z2fie+Tzgl2bCEdERpnwK/7kVdnxuNvO07dpwn0dEpBVp8JmqfD4fsbGxvPrqqwwZMoTx48fz8MMP88orr5xym5kzZ5KTk+N/7N+/v6HDlNN44uMtuL0+zusZ3TSH8h5YbfbnyD0A7XrCrf87cyJSrt/V5vOWj8w7iQIUHDH7l4CZjJRzhZl9Ru7brhlORUTqUY1qRqKjo7HZbKSnp1danp6eTnx81RNftW/fHofDUalJpm/fvqSlpeF2u3E6nSdt43K5cLnqcNtkqTfLt2XwxZZ07FYLs8f1a3pDeX1eeHei2Vek4xC46T1zhtLqSjzP7DNSeAT2fgvdLoTNi8ybxMUPNCcnO57FYt6tVkRE6k2NakacTidDhgwhOTnZv8zn85GcnMzIkSOr3Gb06NHs3LkTn8/nX7Z9+3bat29fZSIiTYe71MfvPzZn/pw8KpEesU1w1Mj+HyH3oNlHZOLimiUiUNZUc6X5uvzeLhvKmmgG/qr+4hQRkVOqcTPNjBkzeO211/jXv/7Fli1buPPOOykoKOCWW24BYOLEiZU6uN55550cPXqUe+65h+3bt7NkyRKeeuoppk2bVn+fQhrEv77fw+7MAqJDnfzf2CY6eqY8geh9ee3n3eh3jfm85SPzpnf7fwAs0P+6+ohQRETOoMbzjIwfP57MzExmzZpFWloagwcP5rPPPvN3at23bx/W425ZnpCQwOeff85vfvMbBg4cSMeOHbnnnnt48MEH6+9TSL3LyCvmL8k7AHggqQ/hQbUblt2gfD7YvNh8Xd73oza6nm/OslqQCUvuK1t2HoR3qHuMIiJyRrpRnlTpt++t5701BxjYKYIP7hqN1drE+ooA7F8F/xwLzjBzSndHUO339eE0c2r4cle9COfcXPcYRURasepev1vpfd/ldFL2Z/PeGvP+M49ddVbTTEQANn9gPve+tG6JCEC/ayte21zQ76q67U9ERKpNyYhU4vMZPLb4JwB+cU5Hzmmq958xjPppoinX7QIIijRf97rE7BArIiKNQsmIVLJo3UFS9mfTxmnjoUv7BDqcUzu0DnL2mTOrdr+47vuzOWDIZLDYYPjtdd+fiIhUW407sErLlV9SytOfmTPpTr+oJ7HhdWz6aEjlo2h6XgLOkPrZ58Wz4bz7IEj9kkREGpNqRsTvX9/vITOvhMR2IUz5WWKgwzk1w4At9dhEU85qVSIiIhIASkYEMPuKvL1yH2DWirjsjXD/mZyDUJxT8+3SN5nzgdiDzJoRERFp1pSMCADf7MziwLEiwoPsXDmwfcMfMHM7vDgM5g6Ag2tqtm15E02PsbWf6ExERJoMJSMCwIIf9wLwi3M6Nc5def/3MHgKzJqRN66B/Surt51hwE8fmK/rs4lGREQCRsmIkJ5bzBdbMgC4aUTnhj/gzmTY8T+w2s2b25XkwpvXwp7vzrxt5lY4sgNsTuiV1PCxiohIg1MyIry3ej9en8HQLlH0imvgm+F5S+Hzh83Xw/8fTPrInI7dnQ9vXQ+7vzr99t/ONZ+7X6S5QEREWgglI62c12fw9sr9ANw4vBFqRdbOh8wtENwWLvgtONvATe+ac4V4CmHBr2D38qq33fIRbFgIFiucd3/DxyoiIo1CyUgr982OTA5mFxER7OCKhu64WpQNXz5lvr5wpnlzOgBHMNywAHpdCqXFsHACHEqpvG1+Jnx0r/l69L2QMKxhYxURkUajZKSVW/CjOZz3F+d0bPiOq18/A4VHILo3DL2l8jpHEPzqjcpNNkd3m+sMAz66BwqzIK4/XPhQw8YpIiKNSslIK5aeW0zy1rKOqw3dRHNkF/z4d/N10pPm9Osnsrtg/FsQPwAKMs1OrfkZsP5t2LYErA649u9mORERaTE0HXwr9u4qs+PqsMQoejZEx1XDMOcQWTMfNr0PPo85N0jPn596m6BwmPBfeP0SOLbHTEiyzdobxsyE+P71H6eIiASUkpFWyuP1sXBVA3VcNQxIeQt+eNmcLbVcbD+4/Nkzbx8WB79+H15Pqti+0zAYdU/9xikiIk2CkpFWauHKfRzMLiI61MnlA+q54+rG/8CH08zX9iDodw0MmQSdR4LFUr19tOsOE/4D868031/zCtj0dRURaYn0694KFZSU8pfkHQDcc3HP+u246i6ApbPM18Nug4seqRg1U1MdBsO9G8BXCqGx9RaiiIg0LUpGWqF/fJNKVr6bxHYh3FDfTTTfzoW8QxDZGS550hwlUxchbeslLBERabo0mqaVOZJfwqtf7wLgvkt647DV41fg2F74/gXzdX0kIiIi0iooGWll/rpsJwVuLwM6RnBFffcVWTrLnLQs8TzoO65+9y0iIi2WkpFWZN+RQt4quzvvQ5f1wWqtZmfS6tjzLWz+wJyq/dKnq99RVUREWj0lI63Ic0u34fEanNczmtE9outvxz4vfFo2K+qQWzQXiIiI1Ig6sLYSGw/k8GHKIQAevLRP9TcsyYesbRAUCSHtzDvlWizgKTJnVT2yw7yxXfpGc92YhxskfhERabmUjLQCqVkFTH1jNQBXDepA/44R1d/4javh4OqK91Y7uMKh6BhgVC574Uxo067uAYuISKuiZKSFS80q4IZXV5CeW0LP2FBmjetX/Y1L8isSEUcb8BSYc34UHTWXBUVCdE9o1xO6jILBE+o9fhERafmUjLRguzPzufG1H/yJyIKp5xIdWoObzGVuM5/bxMJvd4Cn2ExEirLNSchC2qmjqoiI1JmSkRZqV2Y+N776Axl5JfSKq0UiApCx2XyO7Ws+O4LA0QHCO9RvsCIi0qppNE0LlF3o5qbXzESkd1xY7RIRgIwt5nNsDZp2REREakg1Iy3Q3C92kJ5bQtfoNiyYOoJ2tUlEADLLk5G+9ReciIjICVQz0sJsT8/jzR/Mic3+cE3/2icioJoRERFpFEpGWhDDMHji4814fQaX9Iur28RmhUch77D5OqZ3/QQoIiJSBSUjLUjylgy+2ZGF02bl4Svq2LSSudV8jugMQeF1D05EROQUlIy0ECWlXv6wxBz9MuVnXenSrs2ZN0r9BnZ+UfW6E0fSiIiINBB1YG0h/vX9HvYcKSQmzMX0i3qceYPiXHjrevB64N6NENGx8voMdV4VEZHGoZqRFiAzr4QXkncC8EBSb0Jd1cgx9/8IpcVgeGH3lyevV+dVERFpJEpGWoDnl24jv6SUgZ0iuO6cTtXbaM+3Fa93nZCMGMZxzTQ1uKmeiIhILSgZaeZ2ZuTxzqr9AMy6sh9WazWnZ9/7XcXr3cvB56t4n59u3gjPYoXoXvUXrIiISBWUjDRzf/psGz4DLukXx9DEttXbyF0Ah9aZr60OKMyC9I0V68trRdp2A0dw/QYsIiJyAiUjzdiavUf53+Z0rBZ44NLj5gLxFMFrF8M7vzabXE60f6V5993wTtD9InPZ8U016rwqIiKNSMlIM2UYBnM+MecCGT8sgR6xYRUrd/wPDq6GLR9B2saTNy5vokkcXZGM7K4qGVHnVRERaXhKRpqpL7ZksHrvMYIcVu65+IR+HZs/rHi98b2TN95Tlox0GQ3dx5iv964wa1RANSMiItKolIw0Q6VeH3/6zKwVmTK6K/ERQRUrPcWw/fOK95ver9w51VNs1poAJP7M7KAa1gG8JbD3e7Ns+eyrqhkREZFGoGSkGXp/7UF2ZOQTGeLgjgu7V165axm48yGsPbjCIfeAOadIuYOrweuG0Dizg6rFUrmpJme/ub3Naa4XERFpYEpGmplij5fnl24HYPqYHoQHOSoX2LLYfO53DfS50nx9fFPN8U00lrJhwOVNNbuWVzTRRPcC2wn7FhERaQBKRpqZpZvTScstpkNEEDeP7FJ5Zakbtn1ivu53FQy43ny9+QNz2neAvWWTnSWOrtiu6wXmc/pGSP3KfK3+IiIi0kiUjDQzn246DMA1Z3fEZbdVXpn6NRTnmE0wCSPMJKNNDBQeMSc2K3XD/lVm2S4/q9guNAbiB5qv175pPisZERGRRqJkpBkpcnv5cmsmAJcPaH9ygS1lo2j6XAlWG9jsZnMNwMb/mBOdlRZBSDTE9K68bXlTjTvPfFbnVRERaSRKRpqRr7ZnUOTx0ikqmLM6hFde6S2FLR+br/tdVbF8wC/N560fw84vzNddRlX0FynXbUzl96oZERGRRqJkpBn5ZGMaYNaKWE5MJvZ+B0VHIbht5SaYhOEQ0dkcIfPD38xliT/jJJ1Hgr1siLCjjbmNiIhII1Ay0kwUe7wkb0kH4NL+8ScXKB9F0+cKs3mmnMUCA64zX7vzzecuo07e3hFUsTy2D1j11RARkcahK04z8e2OLArcXtpHBDG4U2TllT6fOfU7QL+rT964//UVr4MiIfasqg9SPhQ44dy6hisiIlJt9jMXkabgk7JRNFf0i8Ka/Jg5dXvbrubEZCV5kJ8OroiKYbrHizsLYvqYM6t2GXXqWo8ht0BUojkSR0REpJEoGWkG3KU+lm5OBwzuyHkB1i2qumDvy8DuPHm5xQIjp8Pi6TDohlMfyGqFHhfXS8wiIiLVpWSkGfh+VxZ5xaXcH/IJ0bsXgcUGQ6dAfhoc3QPHUsFXai47lXNuhoG/Arur0eIWERGpDiUjzcCnG9NIsq5iuu8tc8Hlz8CwWysKGAb4vJU7rlZFiYiIiDRBSkaaOI/Xx56fVjDPUTYsd/j/q5yIgNkMc6ZEREREpInSaJombu1PW/mz72lCLCX4ul0ESU8FOiQREZF6Vatk5KWXXiIxMZGgoCBGjBjBypUrq7XdwoULsVgsXHPNNbU5bKsUkjyTDpajZLi6YP3lPNWAiIhIi1PjZOSdd95hxowZzJ49m7Vr1zJo0CCSkpLIyMg47XZ79uzh/vvv57zzzqt1sK3NgWOFtMveCED6eU9BcGRgAxIREWkANU5Gnn/+eaZOncott9xCv379eOWVVwgJCeH1118/5TZer5cJEybw+OOP061btzoF3Jo898lG4jkKQP/BwwMcjYiISMOoUTLidrtZs2YNY8eOrdiB1crYsWNZsWLFKbf7/e9/T2xsLLfeeuspyxyvpKSE3NzcSo/WZvWeo6zftAGrxcDraIOlTUygQxIREWkQNUpGsrKy8Hq9xMXFVVoeFxdHWlpaldt8++23/POf/+S1116r9nHmzJlDRESE/5GQkFCTMJs9n8/g9x9vprPFbPqyte168l12RUREWogGHU2Tl5fHzTffzGuvvUZ0dHS1t5s5cyY5OTn+x/79+xswyqbn/XUH2XAgh56OLHNBVGJA4xEREWlINRqaER0djc1mIz09vdLy9PR04uNPvpPsrl272LNnD+PGjfMv8/l85oHtdrZt20b37t1P2s7lcuFytc4JugpKSvnTZ1sBuDKhBA6gZERERFq0GtWMOJ1OhgwZQnJysn+Zz+cjOTmZkSNHnlS+T58+bNy4kZSUFP/jqquuYsyYMaSkpLS65pfqeHn5LjLySujcNoT+IWbnVSUjIiLSktV40ooZM2YwadIkhg4dyvDhw5k7dy4FBQXccsstAEycOJGOHTsyZ84cgoKC6N+/f6XtIyMjAU5aLrD5UC6vfrMbgN9d3hfb13vNFW27BjAqERGRhlXjZGT8+PFkZmYya9Ys0tLSGDx4MJ999pm/U+u+ffuwnuoW9XJKX2/P5K631uIu9TGqezuS+sXCh3vMlVFKRkREpOWyGIZhBDqIM8nNzSUiIoKcnBzCw8MDHU69e3f1fn73/kZKfQYjurbl7zcPIdJ7DJ7rBRYrPJwOdmegwxQREamR6l6/Nbd4ABmGwZ+XbueFZTsBuHpwB/50/UBcdhvs22MWCu+kRERERFo0JSMB9PhHm5n//R4Apo/pwX2X9MJSPp/IsVTzuW1iQGITERFpLEpGAiQrv4Q3fzA7qM75xQBuHN65coFje8xnjaQREZEWTj1NA+STjYfx+gwGdYo4OREBOFpWM6JkREREWjglIwHywbqDAFw1uGPVBfw1IxpJIyIiLZuSkQDYd6SQtfuysVhg3MD2VRdSM42IiLQSSkYC4KMNhwAY1b0dseFBJxdwF0J+2Y0HNeGZiIi0cEpGGplhGP4mmqsHnaKJJrts5tWgCAiOaqTIREREAkPJSCPbmpbHjox8nDYrSf1PvrkgcFznVdWKiIhIy6dkpJF9mGI20YzpE0NEsKPqQuovIiIirYiSkUbk8xl8tN5MRq4+1SgaqJjwTMmIiIi0AkpGGtGafcc4mF1EmMvORX1iT12wvGZEnVdFRKQVUDLSiD5MMTuuJvWPJ8hhO3VBNdOIiEgromSkkXi8PpZsOAyYN8Q7JZ8PjpWNplEHVhERaQWUjDSSb3ZkcqzQQ3Soi5Hd2p26YN5h8JaA1Q7hp+lXIiIi0kIoGWkk/11rNtFcObA9dttpTnt559XIzmDTfQxFRKTlUzLSCHIKPSzdnA7A9UM6nb6w+ouIiEgro2SkEXy04RDuUh994sM4q0P46Qvrbr0iItLKKBlpBP9dewAwa0UsFsvpC+tuvSIi0sooGWlguzLzWbcvG5vVcvqJzsqpmUZERFoZJSMN7L9rzFqRC3vFEBPmOvMG5R1YNeGZiIi0EkpGGpDXZ/B+2SiaM3ZcBSjOhcIj5uvILg0YmYiISNOhZKQBfb8ri7TcYiKCHVzU9zTTv5crb6IJaQdBZ+joKiIi0kIoGWlA/ylrorl6cAdc9tNM/17Of4M8NdGIiEjroWSkgRTs/oGCnz7Dgo/rzqlGEw1A5jbzObpXwwUmIiLSxGiKz4aw7VOCF07gHzYvexwJdDk2CzpeB9Yz1I5kbjWfY3o3fIwiIiJNhGpG6lvqN/DuJKyGF49hI9G3H8v7U+HFYbDuLfB5T71tRlkyEtu3cWIVERFpApSM1KeDa+HtG8Fbwv+8Qxjh/hv5ox+C4LZwdBd8eBd8+3zV23pL4cgO83VMn8aLWUREJMCUjNSXzG3w7+vAnUdq2BDu9tzNOX16EPrzmXDvRhhxp1lu6ydVb390N3jd4GgDEQmNF7eIiEiAKRmpDzkH4M1roegovvbnMCH/HkpwMmFEZ3O9KxSGTzVfp/8EXs/J+/D3F+kFVv2ziIhI66GrXn344WXIPQjRvfl08IscKrLTMTKY83vFVJSJ6gqucPCWVIyaOZ4/GVF/ERERaV2UjNSH8uRi5DT+tS4XgPHDErBZj7spntUK7QeZrw+nnLyPjC3mc6z6i4iISOuiZKQ+HN0FwEFrPCv3HMVmtfCroVX0+/AnI+tPXqeaERERaaWUjNSV1wPH9gLw7m7zRngX9YklPiLo5LLlycihlJP3kVU+kkZzjIiISOuiZKSusveB4cVwhDB/YwkAN5V3XD1R+8Hmc9rGyvONHE0Fn0cjaUREpFVSMlJXR8wmmtzgTuQUl5odV3vGVF22XXcz4SgtqqgJAcgs6y8S01sjaUREpNXRla+uyvqLbCkxE5AbTuy4ejyrDdoPNF8f34lVM6+KiEgrpmSkrspqRtYWtDM7rg47QzNLVZ1Y/TUjGkkjIiKtj5KRuiqrGUk14rm4Tyxx4VV0XD1elclI2dBgJSMiItIKKRmpq7KakT2+eK4Y2P7M5cs7sR7eAD5f5ZE0mmNERERaIXugA2jWSt0YOfuxAHuMeEZ2b3fmbaJ7gT0Y3Hnm/WgMrzmSxhmqkTQiItIqqWakLo7twWL4yDeCiIrtSGzYGZpoAGx2iO9vvj6cUjHzakxvsJyi46uIiEgLpmSkLsr6i+wx4hnV4xTDeaty/LTw6i8iIiKtnJpp6uJIRTIyukd09bfz9xtZDyFlTTtKRkREpJVSzUgd5B82azX2GPGM6Na2+hseP6LGf4M8zTEiIiKtk2pG6qDg8HZCAW9UN8KDHNXfMKYP2JxQnGM+ypeJiIi0QqoZqQNHdioAMZ1rmEjYnRB3VsV7ZyhEdKrHyERERJoPJSO1ZHiKiCzNAKBn30E130H747bRSBoREWnFlIzU0r5dm7FikGcEM6BXj5rvoLwTK0CM+ouIiEjrpWSklnZt3QBAprMTQc5adL05vmZEM6+KiEgrpmSklo7sM0fBlEZ2q90OYvuBtSyJUc2IiIi0YkpGasHrM/wTnoV37F27nTiC4JxJED8AOo+ox+hERESaFw3trYVNB3Po6D0ENojpUodajSufr7+gREREminVjNTCd7uySLSmAWCL7hngaERERJo3JSO1sHr7QTpYjppv2nUPbDAiIiLNnJKRGiop9ZK5bysAXlcEhNRgGngRERE5iZKRGkrZl00H3yEArNG1mF9EREREKlEyUkM/7D5KV4vZX8TSVk00IiIidaVkpIZ+TD1CYlkyov4iIiIidVerZOSll14iMTGRoKAgRowYwcqVK09Z9rXXXuO8884jKiqKqKgoxo4de9ryTVlJqZc1e4/RtWwkDW1rOeGZiIiI+NU4GXnnnXeYMWMGs2fPZu3atQwaNIikpCQyMjKqLL98+XJuvPFGvvzyS1asWEFCQgKXXHIJBw8erHPwjW39/hxKSn10s6abC9RMIyIiUmcWwzCMmmwwYsQIhg0bxosvvgiAz+cjISGBu+++m4ceeuiM23u9XqKionjxxReZOHFitY6Zm5tLREQEOTk5hIeH1yTcevXX5B38fWkKm4JuMxc8uAeCowIWj4iISFNW3et3jWpG3G43a9asYezYsRU7sFoZO3YsK1asqNY+CgsL8Xg8tG176iGxJSUl5ObmVno0BT+kHuEXtm/MN1FdlYiIiIjUgxolI1lZWXi9XuLi4iotj4uLIy0trVr7ePDBB+nQoUOlhOZEc+bMISIiwv9ISEioSZgNwl3qY/3eTG63LzEXjJwW2IBERERaiEYdTfP000+zcOFCFi1aRFBQ0CnLzZw5k5ycHP9j//79jRhl1TYcyObn3u/oZMnCaBMDZ/860CGJiIi0CDW6UV50dDQ2m4309PRKy9PT04mPjz/tts8++yxPP/00X3zxBQMHDjxtWZfLhcvlqkloDe6HXZncaV8MgOXcO8ERHOCIREREWoYa1Yw4nU6GDBlCcnKyf5nP5yM5OZmRI0eecrs//elPPPHEE3z22WcMHTq09tEGkHvzp/SyHsRtD4VhtwU6HBERkRajRjUjADNmzGDSpEkMHTqU4cOHM3fuXAoKCrjlllsAmDhxIh07dmTOnDkA/PGPf2TWrFksWLCAxMREf9+S0NBQQkND6/GjNBy3x8tFWf8GC+QPmEjboIhAhyQiItJi1DgZGT9+PJmZmcyaNYu0tDQGDx7MZ5995u/Uum/fPqzWigqXl19+GbfbzfXXX19pP7Nnz+axxx6rW/SNJHXt5wy27KAEB1EX3RPocERERFqUGs8zEgiBnmdk718uo8ux7/k6fBznz/h3ox9fRESkOWqQeUZapcPr6XLse7yGhcyBdwQ6GhERkRZHycgZ+Fb+E4CPfSPp339QgKMRERFpeZSMnEHhwU0AfGcfQc/Y5tHhVkREpDlRMnIm2fsAiOrQE6vVEuBgREREWh4lI6fjKSbUnQlAlx59AxyMiIhIy6Rk5DRKj5m1IgWGi7N7dw9wNCIiIi2TkpHT2LtrKwCHLbH0jm/8IcUiIiKtgZKR0ziYugWAgpCO6i8iIiLSQJSMnEZe2m4A7G27BDgSERGRlkvJyCl4fQaWHLPPSNuOPQMcjYiISMulZOQUNh/Kpb2RAUBs514BjkZERKTlUjJyCj+mHqGTxRzWa4tSM42IiEhDUTJyCmt2HibGkmO+UTIiIiLSYJSMVMHrMzi01xzW63WEQVBkYAMSERFpwZSMVGFrWi5R7jQArFGdwaJhvSIiIg3FHugAmqIfdx/19xexRCUGNhgRafZ8Ph9utzvQYYjUO4fDgc1mq/N+lIxU4cfUI5xdlowQ2TmwwYhIs+Z2u0lNTcXn8wU6FJEGERkZSXx8PJY6tCIoGTmBz2ewMvUo45SMiEgdGYbB4cOHsdlsJCQkYLWqZVxaDsMwKCwsJCPDnAajffv2td6XkpETbM/I41ihh86uLHOBRtKISC2VlpZSWFhIhw4dCAkJCXQ4IvUuODgYgIyMDGJjY2vdZKM0/QQ/7j4KQKKtLBlRzYiI1JLX6wXA6XQGOBKRhlOeaHs8nlrvQ8nICX5MPUIIxYT7yuYYUTIiInVUl7Z0kaauPr7fSkaOYxhmf5HykTQERUJQREBjEhERaemUjBxnV2Y+WfluutrVRCMiUp8SExOZO3duoMOQJkrJyHF+TDX7i5zbtsBcoGRERFoZi8Vy2sdjjz1Wq/2uWrWK22+/vX6DlRZDo2mOs6osGRnQJhtyAE14JiKtzOHDh/2v33nnHWbNmsW2bdv8y0JDQ/2vDcPA6/Vit5/5UhITE1O/gTYBNfn8cnqqGTnOytTykTRHzAWqGRGRViY+Pt7/iIiIwGKx+N9v3bqVsLAwPv30U4YMGYLL5eLbb79l165dXH311cTFxREaGsqwYcP44osvKu33xGYai8XCP/7xD6699lpCQkLo2bMnixcvPm1sb775JkOHDiUsLIz4+Hhuuukm/xwX5X766SeuvPJKwsPDCQsL47zzzmPXrl3+9a+//jpnnXUWLpeL9u3bM336dAD27NmDxWIhJSXFXzY7OxuLxcLy5csBWL58ORaLpVafv6SkhAcffJCEhARcLhc9evTgn//8J4Zh0KNHD5599tlK5VNSUrBYLOzcufO056SlUDJS5sCxQg7lFGO3WmjrMe9Lo2REROqTYRgUuksD8jAMo94+x0MPPcTTTz/Nli1bGDhwIPn5+Vx++eUkJyezbt06Lr30UsaNG8e+fftOu5/HH3+cX/3qV2zYsIHLL7+cCRMmcPTo0VOW93g8PPHEE6xfv54PPviAPXv2MHnyZP/6gwcPcv755+NyuVi2bBlr1qxhypQplJaWAvDyyy8zbdo0br/9djZu3MjixYvp0aNHo3z+iRMn8vbbb/PCCy+wZcsW/v73vxMaGorFYmHKlCnMmzev0jHmzZvH+eefX6v4miPVLZUprxU5q2ME1uy95sJITXgmIvWnyOOl36zPA3Lszb9PIsRZPz/5v//97/n5z3/uf9+2bVsGDRrkf//EE0+waNEiFi9e7K95qMrkyZO58cYbAXjqqad44YUXWLlyJZdeemmV5adMmeJ/3a1bN1544QWGDRtGfn4+oaGhvPTSS0RERLBw4UIcDgcAvXr18m/zhz/8gfvuu4977rnHv2zYsGE1/PQ1//zbt2/n3XffZenSpYwdO9Yf//HnYdasWaxcuZLhw4fj8XhYsGDBSbUlLZlqRsqs2mMmI+cnOKE421wYmRC4gEREmqihQ4dWep+fn8/9999P3759iYyMJDQ0lC1btpyxZmTgwIH+123atCE8PPykZpfjrVmzhnHjxtG5c2fCwsK44IILAPzHSUlJ4bzzzvMnIsfLyMjg0KFDXHzxxdX+nKdS08+fkpKCzWbzx3uiDh06cMUVV/D6668D8NFHH1FSUsIvf/nLOsfaXKhmpEz5SJrR0YXmguC24AoLYEQi0tIEO2xs/n1SwI5dX9q0aVPp/f3338/SpUt59tln6dGjB8HBwVx//fVnvFPxiUmDxWI55Q0FCwoKSEpKIikpibfeeouYmBj27dtHUlKS/zjlU5NX5XTrAP99g45vzjrVjKI1/fxnOjbAbbfdxs0338yf//xn5s2bx/jx41vVLQSUjABZ+SXszjSH8/Zvk20u1D1pRKSeWSyWemsqaUq+++47Jk+ezLXXXguYNQV79uyp12Ns3bqVI0eO8PTTT5OQYNZar169ulKZgQMH8q9//QuPx3NSohMWFkZiYiLJycmMGTPmpP2Xj/Y5fPgwZ599NkClzqync6bPP2DAAHw+H1999ZW/meZEl19+OW3atOHll1/ms88+4+uvv67WsVsKNdNQMaS3T3wYoUWHzIXqvCoiUi09e/bk/fffJyUlhfXr13PTTTedsoajtjp37ozT6eSvf/0ru3fvZvHixTzxxBOVykyfPp3c3FxuuOEGVq9ezY4dO3jzzTf9Q5Mfe+wxnnvuOV544QV27NjB2rVr+etf/wqYtRfnnnuuv2PqV199xSOPPFIvnz8xMZFJkyYxZcoUPvjgA1JTU1m+fDnvvvuuv4zNZmPy5MnMnDmTnj17MnLkyLqesmZFyQiwsqy/yLDEtpBd1sapzqsiItXy/PPPExUVxahRoxg3bhxJSUmcc8459XqMmJgY5s+fz3vvvUe/fv14+umnT+rg2a5dO5YtW0Z+fj4XXHABQ4YM4bXXXvPXkkyaNIm5c+fyt7/9jbPOOosrr7ySHTt2+Ld//fXXKS0tZciQIdx777384Q9/qFZs1fn8L7/8Mtdffz133XUXffr0YerUqRQUFFQqc+utt+J2u7nllltqc4qaNYtRn+O9Gkhubi4RERHk5OQQHh5e7/u/4oVv+OlQLn+98WzGbb4fti2By5+F4VPr/Vgi0noUFxeTmppK165dCQoKCnQ40sR98803XHzxxezfv5+4uLhAh1Ntp/ueV/f63eprRnKLPWw5nAvA8K6qGRERkcZVUlLCgQMHeOyxx/jlL3/ZrBKR+tLqk5E1e4/hM6BLuxDiwoMqkhF1YBURkUbw9ttv06VLF7Kzs/nTn/4U6HACotUnI+WdV4cntoWiY1CSY66I0BwjIiLS8CZPnozX62XNmjV07Ngx0OEERKtPRspnXh3WtS0c3W0ubBMDztYzvltERCSQWnUyUuzxsuGAWRMyomtb2Jlsrug49DRbiYiISH1q1clIyv5s3F4fsWEuOrcNga1LzBV9rghsYCIiIq1Iq05G/P1FurbFknsQDqcAFuhV9U2aREREpP616mSkfLKz4V3bwrZPzYWdz4XQmABGJSIi0rq06mQk1GWnjdNmJiNbPzYX9r48sEGJiIi0Mq06GXn510NYP/sSekd4Yc+35kL1FxERqbMLL7yQe++91/8+MTGRuXPnnnYbi8XCBx98UOdj19d+pPG06mQEwG6zYtmZDL5SiOkD7boHOiQRkYAZN24cl15adb+5b775BovFwoYNG2q831WrVnH77bfXNbxKHnvsMQYPHnzS8sOHD3PZZZfV67GkYbX6ZARQE42ISJlbb72VpUuXcuDAgZPWzZs3j6FDhzJw4MAa7zcmJoaQkMaZvyk+Ph6Xy9Uox2pK3G53oEOoNSUjpSWw4wvzdZ8rAxuLiEiAXXnllf475B4vPz+f9957j1tvvZUjR45w44030rFjR0JCQhgwYABvv/32afd7YjPNjh07OP/88wkKCqJfv34sXbr0pG0efPBBevXqRUhICN26dePRRx/F4/EAMH/+fB5//HHWr1+PxWLBYrH4Yz6xmWbjxo1cdNFFBAcH065dO26//Xby8/P96ydPnsw111zDs88+S/v27WnXrh3Tpk3zH6squ3bt4uqrryYuLo7Q0FCGDRvGF198UalMSUkJDz74IAkJCbhcLnr06ME///lP//qffvqJK6+8kvDwcMLCwjjvvPPYtWsXcHIzF8A111zD5MmTK53TJ554gokTJxIeHu6veTrdeSv30UcfMWzYMIKCgoiOjubaa68F4Pe//z39+/c/6fMOHjyYRx999JTno67sDbbn5iL1G3DnQWg8dDg70NGISEtmGOApDMyxHSFgsZyxmN1uZ+LEicyfP5+HH34YS9k27733Hl6vlxtvvJH8/HyGDBnCgw8+SHh4OEuWLOHmm2+me/fuDB8+/IzH8Pl8/OIXvyAuLo4ff/yRnJycky68AGFhYcyfP58OHTqwceNGpk6dSlhYGA888ADjx49n06ZNfPbZZ/4kICIi4qR9FBQUkJSUxMiRI1m1ahUZGRncdtttTJ8+vVLC9eWXX9K+fXu+/PJLdu7cyfjx4xk8eDBTp1Z99/b8/Hwuv/xynnzySVwuF2+88Qbjxo1j27ZtdO7cGYCJEyeyYsUKXnjhBQYNGkRqaipZWVkAHDx4kPPPP58LL7yQZcuWER4eznfffUdpaekZz9/xnn32WWbNmsXs2bOrdd4AlixZwrXXXsvDDz/MG2+8gdvt5pNPPgFgypQpPP7446xatYphw4YBsG7dOjZs2MD7779fo9hqQsnItvKJzi4HqyqKRKQBeQrhqQ6BOfbvDoGzTbWKTpkyhWeeeYavvvqKCy+8EDCbaK677joiIiKIiIjg/vvv95e/++67+fzzz3n33XerlYx88cUXbN26lc8//5wOHczz8dRTT53Uz+ORRx7xv05MTOT+++9n4cKFPPDAAwQHBxMaGordbic+Pv6Ux1qwYAHFxcW88cYbtGljfv4XX3yRcePG8cc//tF/h9yoqChefPFFbDYbffr04YorriA5OfmUycigQYMYNGiQ//0TTzzBokWLWLx4MdOnT2f79u28++67LF26lLFjxwLQrVs3f/mXXnqJiIgIFi5ciMPhAKBXr15nPHcnuuiii7jvvvsqLTvdeQN48sknueGGG3j88ccrfR6ATp06kZSUxLx58/zJyLx587jgggsqxV/fWvfV1+eDrWY2SG+NohERAejTpw+jRo3i9ddfB2Dnzp1888033HrrrQB4vV6eeOIJBgwYQNu2bQkNDeXzzz9n37591dr/li1bSEhI8CciACNHjjyp3DvvvMPo0aOJj48nNDSURx55pNrHOP5YgwYN8iciAKNHj8bn87Ft2zb/srPOOgubzeZ/3759ezIyMk653/z8fO6//3769u1LZGQkoaGhbNmyxR9fSkoKNpuNCy64oMrtU1JSOO+88/yJSG0NHXry7UvOdN5SUlK4+OKLT7nPqVOn8vbbb1NcXIzb7WbBggVMmTKlTnGeSeuuGTm0DvLTwBkGXc8LdDQi0tI5QswaikAduwZuvfVW7r77bl566SXmzZtH9+7d/RfWZ555hr/85S/MnTuXAQMG0KZNG+6999567UC5YsUKJkyYwOOPP05SUpK/FuG5556rt2Mc78SkwGKx4PP5Tln+/vvvZ+nSpTz77LP06NGD4OBgrr/+ev85CA4OPu3xzrTearViGEalZVX1YTk+yYLqnbczHXvcuHG4XC4WLVqE0+nE4/Fw/fXXn3abumrdyUj5KJqeY8He+npei0gjs1iq3VQSaL/61a+45557WLBgAW+88QZ33nmnv//Id999x9VXX82vf/1rwOwDsn37dvr161etffft25f9+/dz+PBh2rdvD8APP/xQqcz3339Ply5dePjhh/3L9u7dW6mM0+nE6/We8Vjz58+noKDAf+H+7rvvsFqt9O7du1rxVuW7775j8uTJ/o6f+fn57Nmzx79+wIAB+Hw+vvrqK38zzfEGDhzIv/71LzweT5W1IzExMRw+fNj/3uv1smnTJsaMGXPauKpz3gYOHEhycjK33HJLlfuw2+1MmjSJefPm4XQ6ueGGG86YwNRV626m2aYmGhGRqoSGhjJ+/HhmzpzJ4cOHK43i6NmzJ0uXLuX7779ny5Yt/L//9/9IT0+v9r7Hjh1Lr169mDRpEuvXr+ebb76pdPEsP8a+fftYuHAhu3bt4oUXXmDRokWVyiQmJpKamkpKSgpZWVmUlJScdKwJEyYQFBTEpEmT2LRpE19++SV33303N998s7+/SG307NmT999/n5SUFNavX89NN91UqSYlMTGRSZMmMWXKFD744ANSU1NZvnw57777LgDTp08nNzeXG264gdWrV7Njxw7efPNNf9PRRRddxJIlS1iyZAlbt27lzjvvJDs7u1pxnem8zZ49m7fffpvZs2ezZcsWNm7cyB//+MdKZW677TaWLVvGZ5991uBNNNCakxHDgAtnwsDx0PPngY5GRKTJufXWWzl27BhJSUmV+nc88sgjnHPOOSQlJXHhhRcSHx/PNddcU+39Wq1WFi1aRFFREcOHD+e2227jySefrFTmqquu4je/+Q3Tp09n8ODBfP/99ycNLb3uuuu49NJLGTNmDDExMVUOLw4JCeHzzz/n6NGjDBs2jOuvv56LL76YF198sWYn4wTPP/88UVFRjBo1inHjxpGUlMQ555xTqczLL7/M9ddfz1133UWfPn2YOnUqBQUFALRr145ly5aRn5/PBRdcwJAhQ3jttdf8tSRTpkxh0qRJTJw40d959Ey1IlC983bhhRfy3nvvsXjxYgYPHsxFF13EypUrK5Xp2bMno0aNok+fPowYMaIup6paLMaJjVJNUG5uLhEREeTk5BAeHh7ocEREqqW4uJjU1FS6du1KUFBQoMMRqTbDMOjZsyd33XUXM2bMOG3Z033Pq3v9bt19RkRERKSSzMxMFi5cSFpa2in7ldQ3JSMiIiLiFxsbS3R0NK+++ipRUVGNckwlIyIiIuIXiN4bterA+tJLL5GYmEhQUBAjRow4qePLid577z369OlDUFAQAwYM8E87KyIiIlLjZOSdd95hxowZzJ49m7Vr1zJo0CCSkpJOOVPd999/z4033sitt97KunXruOaaa7jmmmvYtGlTnYMXERGR5q/Go2lGjBjBsGHD/MOifD4fCQkJ3H333Tz00EMnlR8/fjwFBQV8/PHH/mXnnnsugwcP5pVXXqnWMTWaRkSao/JRBomJiQ0+aZRIoBQWFrJ3797GG03jdrtZs2YNM2fO9C+zWq2MHTuWFStWVLnNihUrThoWlJSUVOn2zicqKSmpNHlNbm5uTcIUEWkSHA4HFouFzMxMYmJi/DOYirQEhmHgdrvJzMzEarXidDprva8aJSNZWVl4vd6TZq2Li4tj69atVW6TlpZWZfm0tLRTHmfOnDmV7iYoItIc2Ww2OnXqxIEDBypNFS7SkoSEhNC5c2es1trPo9okR9PMnDmzUm1Kbm4uCQkJAYxIRKR2QkND6dmzZ5U3ORNp7mw2G3a7vc61fjVKRqKjo7HZbCfdgyA9PZ34+Pgqt4mPj69ReQCXy4XLpRvXiUjLYLPZKt2eXkQqq1GditPpZMiQISQnJ/uX+Xw+kpOTGTlyZJXbjBw5slJ5gKVLl56yvIiIiLQuNW6mmTFjBpMmTWLo0KEMHz6cuXPnUlBQ4J8yduLEiXTs2JE5c+YAcM8993DBBRfw3HPPccUVV7Bw4UJWr17Nq6++Wr+fRERERJqlGicj48ePJzMzk1mzZpGWlsbgwYP57LPP/J1U9+3bV6kTy6hRo1iwYAGPPPIIv/vd7+jZsycffPAB/fv3r79PISIiIs1Ws7hrb05ODpGRkezfv1/zjIiIiDQT5QNQsrOziYiIOGW5Jjma5kR5eXkAGlEjIiLSDOXl5Z02GWkWNSM+n49Dhw4RFhZWr5MGlWdsqnFpeDrXjUfnunHpfDcenevGU1/n2jAM8vLy6NChw2nnIWkWNSNWq5VOnTo12P7Dw8P1xW4kOteNR+e6cel8Nx6d68ZTH+f6dDUi5Wo/XZqIiIhIPVAyIiIiIgHVqpMRl8vF7NmzNdtrI9C5bjw6141L57vx6Fw3nsY+182iA6uIiIi0XK26ZkREREQCT8mIiIiIBJSSEREREQkoJSMiIiISUK06GXnppZdITEwkKCiIESNGsHLlykCH1OzNmTOHYcOGERYWRmxsLNdccw3btm2rVKa4uJhp06bRrl07QkNDue6660hPTw9QxC3D008/jcVi4d577/Uv03muXwcPHuTXv/417dq1Izg4mAEDBrB69Wr/esMwmDVrFu3btyc4OJixY8eyY8eOAEbcPHm9Xh599FG6du1KcHAw3bt354knnuD4sRY617Xz9ddfM27cODp06IDFYuGDDz6otL465/Xo0aNMmDCB8PBwIiMjufXWW8nPz697cEYrtXDhQsPpdBqvv/668dNPPxlTp041IiMjjfT09ECH1qwlJSUZ8+bNMzZt2mSkpKQYl19+udG5c2cjPz/fX+aOO+4wEhISjOTkZGP16tXGueeea4waNSqAUTdvK1euNBITE42BAwca99xzj3+5znP9OXr0qNGlSxdj8uTJxo8//mjs3r3b+Pzzz42dO3f6yzz99NNGRESE8cEHHxjr1683rrrqKqNr165GUVFRACNvfp588kmjXbt2xscff2ykpqYa7733nhEaGmr85S9/8ZfRua6dTz75xHj44YeN999/3wCMRYsWVVpfnfN66aWXGoMGDTJ++OEH45tvvjF69Ohh3HjjjXWOrdUmI8OHDzemTZvmf+/1eo0OHToYc+bMCWBULU9GRoYBGF999ZVhGIaRnZ1tOBwO47333vOX2bJliwEYK1asCFSYzVZeXp7Rs2dPY+nSpcYFF1zgT0Z0nuvXgw8+aPzsZz875Xqfz2fEx8cbzzzzjH9Zdna24XK5jLfffrsxQmwxrrjiCmPKlCmVlv3iF78wJkyYYBiGznV9OTEZqc553bx5swEYq1at8pf59NNPDYvFYhw8eLBO8bTKZhq3282aNWsYO3asf5nVamXs2LGsWLEigJG1PDk5OQC0bdsWgDVr1uDxeCqd+z59+tC5c2ed+1qYNm0aV1xxRaXzCTrP9W3x4sUMHTqUX/7yl8TGxnL22Wfz2muv+denpqaSlpZW6XxHREQwYsQIne8aGjVqFMnJyWzfvh2A9evX8+2333LZZZcBOtcNpTrndcWKFURGRjJ06FB/mbFjx2K1Wvnxxx/rdPxmcaO8+paVlYXX6yUuLq7S8ri4OLZu3RqgqFoen8/Hvffey+jRo+nfvz8AaWlpOJ1OIiMjK5WNi4sjLS0tAFE2XwsXLmTt2rWsWrXqpHU6z/Vr9+7dvPzyy8yYMYPf/e53rFq1iv/7v//D6XQyadIk/zmt6jdF57tmHnroIXJzc+nTpw82mw2v18uTTz7JhAkTAHSuG0h1zmtaWhqxsbGV1tvtdtq2bVvnc98qkxFpHNOmTWPTpk18++23gQ6lxdm/fz/33HMPS5cuJSgoKNDhtHg+n4+hQ4fy1FNPAXD22WezadMmXnnlFSZNmhTg6FqWd999l7feeosFCxZw1llnkZKSwr333kuHDh10rluwVtlMEx0djc1mO2lkQXp6OvHx8QGKqmWZPn06H3/8MV9++SWdOnXyL4+Pj8ftdpOdnV2pvM59zaxZs4aMjAzOOecc7HY7drudr776ihdeeAG73U5cXJzOcz1q3749/fr1q7Ssb9++7Nu3D8B/TvWbUne//e1veeihh7jhhhsYMGAAN998M7/5zW+YM2cOoHPdUKpzXuPj48nIyKi0vrS0lKNHj9b53LfKZMTpdDJkyBCSk5P9y3w+H8nJyYwcOTKAkTV/hmEwffp0Fi1axLJly+jatWul9UOGDMHhcFQ699u2bWPfvn069zVw8cUXs3HjRlJSUvyPoUOHMmHCBP9rnef6M3r06JOGqG/fvp0uXboA0LVrV+Lj4yud79zcXH788Ued7xoqLCzEaq18abLZbPh8PkDnuqFU57yOHDmS7Oxs1qxZ4y+zbNkyfD4fI0aMqFsAder+2owtXLjQcLlcxvz5843Nmzcbt99+uxEZGWmkpaUFOrRm7c477zQiIiKM5cuXG4cPH/Y/CgsL/WXuuOMOo3PnzsayZcuM1atXGyNHjjRGjhwZwKhbhuNH0xiGznN9WrlypWG3240nn3zS2LFjh/HWW28ZISEhxr///W9/maefftqIjIw0PvzwQ2PDhg3G1VdfreGmtTBp0iSjY8eO/qG977//vhEdHW088MAD/jI617WTl5dnrFu3zli3bp0BGM8//7yxbt06Y+/evYZhVO+8XnrppcbZZ59t/Pjjj8a3335r9OzZU0N76+qvf/2r0blzZ8PpdBrDhw83fvjhh0CH1OwBVT7mzZvnL1NUVGTcddddRlRUlBESEmJce+21xuHDhwMXdAtxYjKi81y/PvroI6N///6Gy+Uy+vTpY7z66quV1vt8PuPRRx814uLiDJfLZVx88cXGtm3bAhRt85Wbm2vcc889RufOnY2goCCjW7duxsMPP2yUlJT4y+hc186XX35Z5e/zpEmTDMOo3nk9cuSIceONNxqhoaFGeHi4ccsttxh5eXl1js1iGMdNayciIiLSyFplnxERERFpOpSMiIiISEApGREREZGAUjIiIiIiAaVkRERERAJKyYiIiIgElJIRERERCSglIyIiIhJQSkZEREQkoJSMiIiISEApGREREZGAUjIiIiIiAfX/AS8s7MUs0Mo1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"], label=\"Train accuracy\")\n",
    "\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:35.563713Z",
     "iopub.status.busy": "2024-11-26T16:55:35.563364Z",
     "iopub.status.idle": "2024-11-26T16:55:44.403083Z",
     "shell.execute_reply": "2024-11-26T16:55:44.402143Z",
     "shell.execute_reply.started": "2024-11-26T16:55:35.563674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:44.404698Z",
     "iopub.status.busy": "2024-11-26T16:55:44.404426Z",
     "iopub.status.idle": "2024-11-26T16:55:44.409170Z",
     "shell.execute_reply": "2024-11-26T16:55:44.408201Z",
     "shell.execute_reply.started": "2024-11-26T16:55:44.404672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:44.410526Z",
     "iopub.status.busy": "2024-11-26T16:55:44.410259Z",
     "iopub.status.idle": "2024-11-26T16:55:44.422789Z",
     "shell.execute_reply": "2024-11-26T16:55:44.422023Z",
     "shell.execute_reply.started": "2024-11-26T16:55:44.410499Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 33, 55, ..., 51, 42, 70])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:44.424133Z",
     "iopub.status.busy": "2024-11-26T16:55:44.423820Z",
     "iopub.status.idle": "2024-11-26T16:55:44.432213Z",
     "shell.execute_reply": "2024-11-26T16:55:44.431595Z",
     "shell.execute_reply.started": "2024-11-26T16:55:44.424093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:44.433822Z",
     "iopub.status.busy": "2024-11-26T16:55:44.433262Z",
     "iopub.status.idle": "2024-11-26T16:55:44.442540Z",
     "shell.execute_reply": "2024-11-26T16:55:44.441658Z",
     "shell.execute_reply.started": "2024-11-26T16:55:44.433783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.index.name = \"Id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:44.444313Z",
     "iopub.status.busy": "2024-11-26T16:55:44.443704Z",
     "iopub.status.idle": "2024-11-26T16:55:44.457568Z",
     "shell.execute_reply": "2024-11-26T16:55:44.456654Z",
     "shell.execute_reply.started": "2024-11-26T16:55:44.444274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label\n",
       "Id       \n",
       "0      90\n",
       "1      33\n",
       "2      55\n",
       "3      51\n",
       "4      71"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T16:55:44.459333Z",
     "iopub.status.busy": "2024-11-26T16:55:44.458701Z",
     "iopub.status.idle": "2024-11-26T16:55:44.473823Z",
     "shell.execute_reply": "2024-11-26T16:55:44.472808Z",
     "shell.execute_reply.started": "2024-11-26T16:55:44.459295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"submission_model_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9468663,
     "sourceId": 84511,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
